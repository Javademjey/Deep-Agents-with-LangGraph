{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770449ab",
   "metadata": {},
   "source": [
    "This document is number `5 of 5` documents I have written, based on the `LangChain Academy Deep Agents with LangGraph` course.\n",
    "\n",
    "The course itself has repositories that it provides you with. If my documents are not useful to you, I suggest you check them out.\n",
    "\n",
    "There are now several successful examples of very **capable** and **long-running** agents. They have given these agents the \n",
    "name `“Deep Agents”` because they believe that they are completely different from previous generations of agents. In \n",
    "this course, you will learn what makes them different and build your own Deep Agent.\n",
    "\n",
    "In LangChain, a Deep Agent is built that is simple and configurable, allowing users to build long-running agents quickly and easily.\n",
    "\n",
    "In this course, you will build a **Deep Research Agent** using Deep Agent. The course is divided into seven modules.\n",
    "\n",
    "Each module includes a video lesson that introduces you to the key concepts, along with related workbooks.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86c228",
   "metadata": {},
   "source": [
    "## Deep Agent for Research\n",
    "\n",
    "### Now, we can put everything we have learned together:\n",
    "\n",
    "- We will use `TODOs` to keep track of tasks.\n",
    "- We will use `files` to store raw tool call results.\n",
    "- We will delegate research tasks to `sub-agents` for context isolation.\n",
    "\n",
    "#### Search Tool\n",
    "We'll build a search tool that offloads raw contents to files and returns only a summary to the agent. This is a common pattern for long-running agent trajectories, as we've seen with Manus!\n",
    "\n",
    "#### Core Components\n",
    "1. **Search Execution (run_tavily_search):** Performs the actual web search using Tavily API with configurable parameters for results count and topic filtering.\n",
    "\n",
    "2. **Content Summarization (summarize_webpage_content):** Uses a lightweight model (GPT-4o-mini) to generate structured summaries of webpage content, producing both a descriptive filename and key learnings summary.\n",
    "\n",
    "3. **Result Processing (process_search_results):** Fetches full webpage content via HTTP, converts HTML to markdown using markdownify, and generates summaries for each result.\n",
    "\n",
    "4. **Context Offloading (tavily_search tool):** The main tool that:\n",
    "- Executes search and processes results\n",
    "- Saves full content to files in agent state (context offloading)\n",
    "- Returns only minimal summaries to the agent (prevents context spam)\n",
    "- Uses LangGraph Command to update both files and messages\n",
    "\n",
    "5. **Strategic Thinking (think_tool):** Provides a structured reflection mechanism for agents to analyze findings, assess gaps, and plan next steps in their research workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3996072",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1b98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import uuid, base64\n",
    "\n",
    "import httpx\n",
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState, BaseTool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import InjectedToolArg, InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "from langgraph.types import Command\n",
    "from markdownify import markdownify\n",
    "from pydantic import BaseModel, Field\n",
    "from tavily import TavilyClient\n",
    "from typing_extensions import Annotated, Literal, NotRequired, TypedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8554b",
   "metadata": {},
   "source": [
    "### Reducer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0848293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reducer(left, right):\n",
    "    if left is None:\n",
    "        return right\n",
    "    elif right is None:\n",
    "        return left\n",
    "    else:\n",
    "        return {**left, **right}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f75608d",
   "metadata": {},
   "source": [
    "### Data Models and Type Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dc789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Todo(TypedDict):\n",
    "    content: str\n",
    "    status: Literal[\"pending\", \"in_progress\", \"completed\"]\n",
    "\n",
    "class SubAgent(TypedDict):\n",
    "    name: str                       \n",
    "    description: str                \n",
    "    prompt: str                     \n",
    "    tools: NotRequired[list[str]]   \n",
    "\n",
    "class DeepAgentState(AgentState):\n",
    "    todos: NotRequired[list[Todo]]\n",
    "    files: Annotated[NotRequired[dict[str, str]], file_reducer]\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"Schema for webpage content summarization.\"\"\"\n",
    "    filename: str = Field(description=\"Name of the file to store.\")\n",
    "    summary: str = Field(description=\"Key learnings from the webpage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73789596",
   "metadata": {},
   "source": [
    "### Planning: TODO Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c3123",
   "metadata": {},
   "source": [
    "#### Tool Description - Todo Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8214b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_TODOS_DESCRIPTION= \"\"\" \n",
    "| Create and manage structured task lists for tracking progress through complex workflows.                        │\n",
    "│                                                                                                                 │\n",
    "│  ## When to Use                                                                                                 │\n",
    "│  - Multi-step or non-trivial tasks requiring coordination                                                       │\n",
    "│  - When user provides multiple tasks or explicitly requests todo list                                           │\n",
    "│  - Avoid for single, trivial actions                                                                            │\n",
    "│                                                                                                                 │\n",
    "│  ## Structure                                                                                                   │\n",
    "│  - Maintain one list containing multiple todo objects (content, status, id)                                     │\n",
    "│  - Use clear, actionable content descriptions                                                                   │\n",
    "│  - Status must be: pending, in_progress, or completed                                                           │\n",
    "│                                                                                                                 │\n",
    "│  ## Best Practices                                                                                              │\n",
    "│  - Only one in_progress task at a time                                                                          │\n",
    "│  - Mark completed immediately when task is fully done                                                           │\n",
    "│  - Always send the full updated list when making changes                                                        │\n",
    "│  - Prune irrelevant items to keep list focused                                                                  │\n",
    "│                                                                                                                 │\n",
    "│  ## Progress Updates                                                                                            │\n",
    "│  - Call TodoWrite again to change task status or edit content                                                   │\n",
    "│  - Reflect real-time progress; don't batch completions                                                          │\n",
    "│  - If blocked, keep in_progress and add new task describing blocker                                             │\n",
    "│                                                                                                                 │\n",
    "│  ## Parameters                                                                                                  │\n",
    "│  - todos: List of TODO items with content and status fields                                                     │\n",
    "│                                                                                                                 │\n",
    "│  ## Returns                                                                                                     │\n",
    "│  Updates agent state with new todo list. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891f6e1",
   "metadata": {},
   "source": [
    "#### Write and Read ToDo Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fec5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "@tool(description=WRITE_TODOS_DESCRIPTION ,parse_docstring=True)\n",
    "def write_todos(\n",
    "    todos: list[Todo], tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Create or update the agent's TODO list for task planning and tracking.\n",
    "\n",
    "    Args:\n",
    "        todos: List of Todo items with content and status\n",
    "        tool_call_id: Tool call identifier for message response\n",
    "\n",
    "    Returns:\n",
    "        Command to update agent state with new TODO list\n",
    "    \"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"todos\": todos,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"Updated todo list to {todos}\", tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def read_todos(\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> str:\n",
    "    \"\"\"Read the current TODO list from the agent state.\n",
    "\n",
    "    This tool allows the agent to retrieve and review the current TODO list\n",
    "    to stay focused on remaining tasks and track progress through complex workflows.\n",
    "\n",
    "    Args:\n",
    "        state: Injected agent state containing the current TODO list\n",
    "        tool_call_id: Injected tool call identifier for message tracking\n",
    "\n",
    "    Returns:\n",
    "        Formatted string representation of the current TODO list\n",
    "    \"\"\"\n",
    "    todos = state.get(\"todos\", [])\n",
    "    if not todos:\n",
    "        return \"No todos currently in the list.\"\n",
    "\n",
    "    result = \"Current TODO List:\\n\"\n",
    "    for i, todo in enumerate(todos, 1):\n",
    "        status_emoji = {\"pending\": \"⏳\", \"in_progress\": \"🔄\", \"completed\": \"✅\"}\n",
    "        emoji = status_emoji.get(todo[\"status\"], \"❓\")\n",
    "        result += f\"{i}. {emoji} {todo['content']} ({todo['status']})\\n\"\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02918ac1",
   "metadata": {},
   "source": [
    "#### Todo Usage Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879b10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO_USAGE_INSTRUCTIONS= \"\"\"\n",
    "| Based upon the user's request:                                                                                  │\n",
    "│  1. Use the write_todos tool to create TODO at the start of a user request, per the tool description.           │\n",
    "│  2. After you accomplish a TODO, use the read_todos to read the TODOs in order to remind yourself of the plan.  │\n",
    "│  3. Reflect on what you've done and the TODO.                                                                   │\n",
    "│  4. **CRITICAL: When completing a research/summary task, you MUST provide the actual content requested**        │\n",
    "│     - Do NOT just mark the task as completed                                                                    │\n",
    "│     - Use the search results to create a comprehensive summary/answer                                           │\n",
    "│     - Provide the actual information the user asked for                                                         │\n",
    "│  5. Mark your task as completed ONLY AFTER providing the requested content                                      │\n",
    "│  6. Continue this process until you have completed all TODOs AND provided all requested content                 │\n",
    "│                                                                                                                 │\n",
    "│  IMPORTANT: Always create a research plan of TODOs and conduct research following the above guidelines for ANY  │\n",
    "│  user request.                                                                                                  │\n",
    "│  IMPORTANT: Aim to batch research tasks into a *single TODO* in order to minimize the number of TODOs you have  │\n",
    "│  to keep track of.                                                                                              │\n",
    "│  IMPORTANT: **NEVER mark a research task as completed without providing the actual research results/summary**   │\n",
    "IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the user's question.\n",
    "CRITICAL: You must provide a comprehensive summary/answer based on the search results. Do not just acknowledge that you found information - actually provide the information the user requested.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6776b3",
   "metadata": {},
   "source": [
    "### Context Offloading: Filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf9258",
   "metadata": {},
   "source": [
    "The descriptions in the prompts below describe in detail how they operate:\n",
    "- LS\n",
    "- Read\n",
    "- Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535d5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_DESCRIPTION= \"\"\"\n",
    "| List all files in the virtual filesystem stored in agent state.                                                 │\n",
    "│                                                                                                                 │\n",
    "│  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     │\n",
    "│  and maintain awareness of your file organization.                                                              │\n",
    "│                                                                                                                 │\n",
    "│  No parameters required - simply call ls() to see all available files.                                          |\n",
    "\"\"\"\n",
    "\n",
    "READ_FILE_DESCRIPTION= \"\"\"\n",
    "|  Read content from a file in the virtual filesystem with optional pagination.                                   │\n",
    "│                                                                                                                 │\n",
    "│  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    │\n",
    "│  to avoid context overflow.                                                                                     │\n",
    "│                                                                                                                 │\n",
    "│  Parameters:                                                                                                    │\n",
    "│  - file_path (required): Path to the file you want to read                                                      │\n",
    "│  - offset (optional, default=0): Line number to start reading from                                              │\n",
    "│  - limit (optional, default=2000): Maximum number of lines to read                                              │\n",
    "│                                                                                                                 │\n",
    "│  Essential before making any edits to understand existing content. Always read a file before editing it.        | \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "WRITE_FILE_DESCRIPTION= \"\"\" \n",
    "|  Create a new file or completely overwrite an existing file in the virtual filesystem.                          │\n",
    "│                                                                                                                 │\n",
    "│  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        │\n",
    "│  rewrites. Files are stored persistently in agent state.                                                        │\n",
    "│                                                                                                                 │\n",
    "│  Parameters:                                                                                                    │\n",
    "│  - file_path (required): Path where the file should be created/overwritten                                      │\n",
    "│  - content (required): The complete content to write to the file                                                │\n",
    "│                                                                                                                 │\n",
    "│  Important: This replaces the entire file content. Use edit_file for partial modifications.                     |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579c855",
   "metadata": {},
   "source": [
    "#### File Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aaed857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "@tool(description=LS_DESCRIPTION)\n",
    "def ls(state: Annotated[DeepAgentState, InjectedState]) -> list[str]:\n",
    "    \"\"\"List all files in the virtual filesystem.\"\"\"\n",
    "    return list(state.get(\"files\", {}).keys())\n",
    "\n",
    "@tool(description=READ_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def read_file(\n",
    "    file_path: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    offset: int = 0,\n",
    "    limit: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Read file content from virtual filesystem with optional offset and limit.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the file to read\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        offset: Line number to start reading from (default: 0)\n",
    "        limit: Maximum number of lines to read (default: 2000)\n",
    "\n",
    "    Returns:\n",
    "        Formatted file content with line numbers, or error message if file not found\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    if file_path not in files:\n",
    "        return f\"Error: File '{file_path}' not found\"\n",
    "\n",
    "    content = files[file_path]\n",
    "    if not content:\n",
    "        return \"System reminder: File exists but has empty contents\"\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    start_idx = offset\n",
    "    end_idx = min(start_idx + limit, len(lines))\n",
    "\n",
    "    if start_idx >= len(lines):\n",
    "        return f\"Error: Line offset {offset} exceeds file length ({len(lines)} lines)\"\n",
    "\n",
    "    # Include line numbers, truncate very long lines\n",
    "    result_lines = []\n",
    "    for i in range(start_idx, end_idx):\n",
    "        line_content = lines[i][:2000]\n",
    "        result_lines.append(f\"{i + 1:6d}\\t{line_content}\")\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "@tool(description=WRITE_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def write_file(\n",
    "    file_path: str,\n",
    "    content: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    \"\"\"Write content to a file in the virtual filesystem.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path where the file should be created/updated\n",
    "        content: Content to write to the file\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        tool_call_id: Tool call identifier for message response (injected in tool node)\n",
    "\n",
    "    Returns:\n",
    "        Command to update agent state with new file content\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    files[file_path] = content\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"Updated file {file_path}\", tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbaf86",
   "metadata": {},
   "source": [
    "#### File Usage Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52239755",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_USAGE_INSTRUCTIONS = \"\"\"You MUST follow this exact workflow for every user request:\n",
    "\n",
    "1. **ALWAYS start by calling ls()** to check existing files\n",
    "2. **ALWAYS call write_file()** to save the user's request to \"user_request.txt\" \n",
    "3. **THEN call web_search()** exactly once to gather information\n",
    "4. **ALWAYS call read_file()** to re-read the saved user request\n",
    "5. **ONLY THEN provide your final answer** based on the research and saved request\n",
    "\n",
    "DO NOT skip any steps. DO NOT take shortcuts. This workflow is mandatory.\n",
    "\n",
    "\n",
    "SIMPLE_RESEARCH_INSTRUCTIONS: After completing the required file workflow above, use web_search exactly once and base your answer on both the search results and the saved user request.\n",
    "\n",
    "CRITICAL: You will be marked as FAILED if you:\n",
    "- Skip calling ls() first\n",
    "- Skip saving the user request with write_file()  \n",
    "- Skip reading back the request with read_file()\n",
    "- Use web_search without following the file workflow\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be19b4c",
   "metadata": {},
   "source": [
    "### Context Isolation: Sub-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d348fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_DESCRIPTION_PREFIX = \"\"\"Delegate a task to a specialized sub-agent with isolated context.\n",
    "\n",
    "This tool allows you to delegate specific tasks to specialized sub-agents that run in clean, isolated contexts. Each sub-agent is designed for a specific type of work and has access to only the tools it needs.\n",
    "\n",
    "Available sub-agents:\n",
    "{other_agents}\n",
    "\n",
    "Use this tool when you need to delegate work that requires specialized knowledge or tools. The sub-agent will work in isolation and return its results to you.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e9c4f",
   "metadata": {},
   "source": [
    "#### Create a tool to use Sub Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb3606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_task_tool(tools, subagents: list[SubAgent], model, state_schema):\n",
    "    \"\"\"Create a task delegation tool that enables context isolation through sub-agents.\n",
    "\n",
    "    This function implements the core pattern for spawning specialized sub-agents with\n",
    "    isolated contexts, preventing context clash and confusion in complex multi-step tasks.\n",
    "\n",
    "    Args:\n",
    "        tools: List of available tools that can be assigned to sub-agents\n",
    "        subagents: List of specialized sub-agent configurations\n",
    "        model: The language model to use for all agents\n",
    "        state_schema: The state schema (typically DeepAgentState)\n",
    "\n",
    "    Returns:\n",
    "        A 'task' tool that can delegate work to specialized sub-agents\n",
    "    \"\"\"\n",
    "    # Create agent registry\n",
    "    agents = {}\n",
    "\n",
    "    # Build tool name mapping for selective tool assignment\n",
    "    tools_by_name = {}\n",
    "    for tool_ in tools:\n",
    "        if not isinstance(tool_, BaseTool):\n",
    "            tool_ = tool(tool_)\n",
    "        tools_by_name[tool_.name] = tool_\n",
    "\n",
    "    # Create specialized sub-agents based on configurations\n",
    "    for _agent in subagents:\n",
    "        if \"tools\" in _agent:\n",
    "            # Use specific tools if specified\n",
    "            _tools = [tools_by_name[t] for t in _agent[\"tools\"]]\n",
    "        else:\n",
    "            # Default to all tools\n",
    "            _tools = tools\n",
    "        agents[_agent[\"name\"]] = create_react_agent(\n",
    "            model, prompt=_agent[\"system_prompt\"], tools=_tools, state_schema=state_schema\n",
    "        )\n",
    "\n",
    "    # Generate description of available sub-agents for the tool description\n",
    "    other_agents_string = [\n",
    "        f\"- {_agent['name']}: {_agent['description']}\" for _agent in subagents\n",
    "    ]\n",
    "\n",
    "    @tool(description=TASK_DESCRIPTION_PREFIX.format(other_agents=other_agents_string))\n",
    "    def task(\n",
    "        description: str,\n",
    "        subagent_type: str,\n",
    "        state: Annotated[DeepAgentState, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        \"\"\"Delegate a task to a specialized sub-agent with isolated context.\n",
    "\n",
    "        This creates a fresh context for the sub-agent containing only the task description,\n",
    "        preventing context pollution from the parent agent's conversation history.\n",
    "        \"\"\"\n",
    "        # Validate requested agent type exists\n",
    "        if subagent_type not in agents:\n",
    "            return f\"Error: invoked agent of type {subagent_type}, the only allowed types are {[f'`{k}`' for k in agents]}\"\n",
    "\n",
    "        # Get the requested sub-agent\n",
    "        sub_agent = agents[subagent_type]\n",
    "\n",
    "        # Create isolated context with only the task description\n",
    "        # This is the key to context isolation - no parent history\n",
    "        state[\"messages\"] = [{\"role\": \"user\", \"content\": description}]\n",
    "\n",
    "        # Execute the sub-agent in isolation\n",
    "        result = sub_agent.invoke(state)\n",
    "\n",
    "        # Return results to parent agent via Command state update\n",
    "        return Command(\n",
    "            update={\n",
    "                \"files\": result.get(\"files\", {}),  # Merge any file changes\n",
    "                \"messages\": [\n",
    "                    # Sub-agent result becomes a ToolMessage in parent context\n",
    "                    ToolMessage(\n",
    "                        result[\"messages\"][-1].content, tool_call_id=tool_call_id\n",
    "                    )\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dcc0d7",
   "metadata": {},
   "source": [
    "#### SubAgent Usage Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22861c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBAGENT_USAGE_INSTRUCTIONS =\"\"\" You can delegate tasks to sub-agents.                                            │\n",
    "│                                                                                                                 │\n",
    "│  <Task>                                                                                                         │\n",
    "│  Your role is to coordinate research by delegating specific research tasks to sub-agents.                       │\n",
    "│  </Task>                                                                                                        │\n",
    "│                                                                                                                 │\n",
    "│  <Available Tools>                                                                                              │\n",
    "│  1. **task(description, subagent_type)**: Delegate research tasks to specialized sub-agents                     │\n",
    "│     - description: Clear, specific research question or task                                                    │\n",
    "│     - subagent_type: Type of agent to use (e.g., \"research-agent\")                                              │\n",
    "│  2. **think_tool(reflection)**: Reflect on the results of each delegated task and plan next steps.              │\n",
    "│     - reflection: Your detailed reflection on the results of the task and next steps.                           │\n",
    "│                                                                                                                 │\n",
    "│  **PARALLEL RESEARCH**: When you identify multiple independent research directions, make multiple **task**      │\n",
    "│  tool calls in a single response to enable parallel execution. Use at most {max_concurrent_research_units}      │\n",
    "│  parallel agents per iteration.                                                                                 │\n",
    "│  </Available Tools>                                                                                             │\n",
    "│                                                                                                                 │\n",
    "│  <Hard Limits>                                                                                                  │\n",
    "│  **Task Delegation Budgets** (Prevent excessive delegation):                                                    │\n",
    "│  - **Bias towards focused research** - Use single agent for simple questions, multiple only when clearly        │\n",
    "│  beneficial or when you have multiple independent research directions based on the user's request.              │\n",
    "│  - **Stop when adequate** - Don't over-research; stop when you have sufficient information                      │\n",
    "│  - **Limit iterations** - Stop after {max_researcher_iterations} task delegations if you haven't found          │\n",
    "│  adequate sources                                                                                               │\n",
    "│  </Hard Limits>                                                                                                 │\n",
    "│                                                                                                                 │\n",
    "│  <Scaling Rules>                                                                                                │\n",
    "│  **Simple fact-finding, lists, and rankings** can use a single sub-agent:                                       │\n",
    "│  - *Example*: \"List the top 10 coffee shops in San Francisco\" → Use 1 sub-agent, store in                       │\n",
    "│  `findings_coffee_shops.md`                                                                                     │\n",
    "│                                                                                                                 │\n",
    "│  **Comparisons** can use a sub-agent for each element of the comparison:                                        │\n",
    "│  - *Example*: \"Compare OpenAI vs. Anthropic vs. DeepMind approaches to AI safety\" → Use 3 sub-agents            │\n",
    "│  - Store findings in separate files: `findings_openai_safety.md`, `findings_anthropic_safety.md`,               │\n",
    "│  `findings_deepmind_safety.md`                                                                                  │\n",
    "│                                                                                                                 │\n",
    "│  **Multi-faceted research** can use parallel agents for different aspects:                                      │\n",
    "│  - *Example*: \"Research renewable energy: costs, environmental impact, and adoption rates\" → Use 3 sub-agents   │\n",
    "│  - Organize findings by aspect in separate files                                                                │\n",
    "│                                                                                                                 │\n",
    "│  **Important Reminders:**                                                                                       │\n",
    "│  - Each **task** call creates a dedicated research agent with isolated context                                  │\n",
    "│  - Sub-agents can't see each other's work - provide complete standalone instructions                            │\n",
    "│  - Use clear, specific language - avoid acronyms or abbreviations in task descriptions                          │\n",
    "│  </Scaling Rules>                                                                                               | \n",
    "\n",
    "SIMPLE_RESEARCH_INSTRUCTIONS: You are a researcher. Research the topic provided to you. \n",
    "\n",
    "IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the provided topic.\n",
    "\n",
    "Your response should be:\n",
    "1. Concise and focused on the specific topic\n",
    "2. Based only on the web search results provided\n",
    "3. Well-structured and informative\n",
    "4. No more than 2-3 paragraphs\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f239db7",
   "metadata": {},
   "source": [
    "### Geting current date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2c4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date in a human-readable format.\"\"\"\n",
    "    now = datetime.now()\n",
    "    # Use cross-platform compatible format (remove leading zero from day)\n",
    "    day = now.day\n",
    "    return now.strftime(f\"%a %b {day}, %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c005d",
   "metadata": {},
   "source": [
    "### Preparing a summary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3947f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization model \n",
    "summarization_model = init_chat_model(model=\"openai:gpt-4o-mini\", api_key= \"sk-proj-***\")\n",
    "tavily_client = TavilyClient(api_key=\"tvly-dev-***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945a797",
   "metadata": {},
   "source": [
    "### The Tavilly function \n",
    "takes parameters and returns one search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3561522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tavily_search(\n",
    "    search_query: str, \n",
    "    max_results: int = 1, \n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\", \n",
    "    include_raw_content: bool = True, \n",
    ") -> dict:\n",
    "    \"\"\"Perform search using Tavily API for a single query.\n",
    "\n",
    "    Args:\n",
    "        search_query: Search query to execute\n",
    "        max_results: Maximum number of results per query\n",
    "        topic: Topic filter for search results\n",
    "        include_raw_content: Whether to include raw webpage content\n",
    "\n",
    "    Returns:\n",
    "        Search results dictionary\n",
    "    \"\"\"\n",
    "    result = tavily_client.search(\n",
    "        search_query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbaa96a",
   "metadata": {},
   "source": [
    "### Summarizing the content of the Tavily search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f33d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SUMMARIZE_WEB_SEARCH = \"\"\"\n",
    "You are an expert research assistant, and your task is to produce a concise, accurate summary of the following web page content for a user conducting research on a particular date.\n",
    "\n",
    "Guidelines:\n",
    "- Focus on the main points, key findings, and important context.\n",
    "- Be clear, factual, and neutral. Do not add opinion or fabrication.\n",
    "- If the text is very long, prioritize what is most relevant and ignore repetition or low-value content.\n",
    "- Respond in 2-3 informative paragraphs summarizing the essence of the page.\n",
    "- Do not include advertisements, navigation menus, copyright text, or unrelated links.\n",
    "- End with a very brief description of the page's purpose or topic, if clear.\n",
    "\n",
    "Today's date: {date}\n",
    "\n",
    "Content to summarize:\n",
    "\"{webpage_content}\"\n",
    "\n",
    "Your summary:\n",
    "\"\"\"\n",
    "\n",
    "def summarize_webpage_content(webpage_content: str) -> Summary:\n",
    "    \"\"\"Summarize webpage content using the configured summarization model.\n",
    "    \n",
    "    Args:\n",
    "        webpage_content: Raw webpage content to summarize\n",
    "        \n",
    "    Returns:\n",
    "        Summary object with filename and summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up structured output model for summarization\n",
    "        structured_model = summarization_model.with_structured_output(Summary)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary_and_filename = structured_model.invoke([\n",
    "            HumanMessage(content=SUMMARIZE_WEB_SEARCH.format(\n",
    "                webpage_content=webpage_content, \n",
    "                date=get_today_str()\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        return summary_and_filename\n",
    "        \n",
    "    except Exception:\n",
    "        # Return a basic summary object on failure\n",
    "        return Summary(\n",
    "            filename=\"search_result.md\",\n",
    "            summary=webpage_content[:1000] + \"...\" if len(webpage_content) > 1000 else webpage_content\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19718e3",
   "metadata": {},
   "source": [
    "### Fielding the content of search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4afb9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_search_results(results: dict) -> list[dict]:\n",
    "    \"\"\"Process search results by summarizing content where available.\n",
    "    \n",
    "    Args:\n",
    "        results: Tavily search results dictionary\n",
    "        \n",
    "    Returns:\n",
    "        List of processed results with summaries\n",
    "    \"\"\"\n",
    "    processed_results = []\n",
    "\n",
    "    # Create a client for HTTP requests\n",
    "    HTTPX_CLIENT = httpx.Client()\n",
    "    \n",
    "    for result in results.get('results', []):\n",
    "        \n",
    "        # Get url \n",
    "        url = result['url']\n",
    "        \n",
    "        # Read url\n",
    "        response = HTTPX_CLIENT.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Convert HTML to markdown\n",
    "            raw_content = markdownify(response.text)\n",
    "            summary_obj = summarize_webpage_content(raw_content)\n",
    "        else:\n",
    "            # Use Tavily's generated summary\n",
    "            raw_content = result.get('raw_content', '')\n",
    "            summary_obj = Summary(\n",
    "                filename=\"URL_error.md\",\n",
    "                summary=result.get('content', 'Error reading URL; try another search.')\n",
    "            )\n",
    "        \n",
    "        # uniquify file names\n",
    "        uid = base64.urlsafe_b64encode(uuid.uuid4().bytes).rstrip(b\"=\").decode(\"ascii\")[:8]\n",
    "        name, ext = os.path.splitext(summary_obj.filename)\n",
    "        summary_obj.filename = f\"{name}_{uid}{ext}\"\n",
    "\n",
    "        processed_results.append({\n",
    "            'url': result['url'],\n",
    "            'title': result['title'],\n",
    "            'summary': summary_obj.summary,\n",
    "            'filename': summary_obj.filename,\n",
    "            'raw_content': raw_content,\n",
    "        })\n",
    "    \n",
    "    return processed_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3314c",
   "metadata": {},
   "source": [
    "### Preparing the final text using fields prepared from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "573920e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def tavily_search(\n",
    "    query: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    max_results: Annotated[int, InjectedToolArg] = 1,\n",
    "    topic: Annotated[Literal[\"general\", \"news\", \"finance\"], InjectedToolArg] = \"general\",\n",
    ") -> Command:\n",
    "    \"\"\"Search web and save detailed results to files while returning minimal context.\n",
    "\n",
    "    Performs web search and saves full content to files for context offloading.\n",
    "    Returns only essential information to help the agent decide on next steps.\n",
    "\n",
    "    Args:\n",
    "        query: Search query to execute\n",
    "        state: Injected agent state for file storage\n",
    "        tool_call_id: Injected tool call identifier\n",
    "        max_results: Maximum number of results to return (default: 1)\n",
    "        topic: Topic filter - 'general', 'news', or 'finance' (default: 'general')\n",
    "\n",
    "    Returns:\n",
    "        Command that saves full results to files and provides minimal summary\n",
    "    \"\"\"\n",
    "    # Execute search\n",
    "    search_results = run_tavily_search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        topic=topic,\n",
    "        include_raw_content=True,\n",
    "    ) \n",
    "\n",
    "    # Process and summarize results\n",
    "    processed_results = process_search_results(search_results)\n",
    "    \n",
    "    # Save each result to a file and prepare summary\n",
    "    files = state.get(\"files\", {})\n",
    "    saved_files = []\n",
    "    summaries = []\n",
    "    \n",
    "    for i, result in enumerate(processed_results):\n",
    "        # Use the AI-generated filename from summarization\n",
    "        filename = result['filename']\n",
    "        \n",
    "        # Create file content with full details\n",
    "        file_content = f\"\"\"# Search Result: {result['title']}\n",
    "\n",
    "**URL:** {result['url']}\n",
    "**Query:** {query}\n",
    "**Date:** {get_today_str()}\n",
    "\n",
    "## Summary\n",
    "{result['summary']}\n",
    "\n",
    "## Raw Content\n",
    "{result['raw_content'] if result['raw_content'] else 'No raw content available'}\n",
    "\"\"\"\n",
    "        \n",
    "        files[filename] = file_content\n",
    "        saved_files.append(filename)\n",
    "        summaries.append(f\"- {filename}: {result['summary']}...\")\n",
    "    \n",
    "    # Create minimal summary for tool message - focus on what was collected\n",
    "    summary_text = f\"\"\"🔍 Found {len(processed_results)} result(s) for '{query}':\n",
    "\n",
    "{chr(10).join(summaries)}\n",
    "\n",
    "Files: {', '.join(saved_files)}\n",
    "💡 Use read_file() to access full details when needed.\"\"\"\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(summary_text, tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20131298",
   "metadata": {},
   "source": [
    "### Think Tool: To guide the model in choosing the right path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36b05a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def think_tool(reflection: str) -> str:\n",
    "    \"\"\"Tool for strategic reflection on research progress and decision-making.\n",
    "\n",
    "    Use this tool after each search to analyze results and plan next steps systematically.\n",
    "    This creates a deliberate pause in the research workflow for quality decision-making.\n",
    "\n",
    "    When to use:\n",
    "    - After receiving search results: What key information did I find?\n",
    "    - Before deciding next steps: Do I have enough to answer comprehensively?\n",
    "    - When assessing research gaps: What specific information am I still missing?\n",
    "    - Before concluding research: Can I provide a complete answer now?\n",
    "    - How complex is the question: Have I reached the number of search limits?\n",
    "\n",
    "    Reflection should address:\n",
    "    1. Analysis of current findings - What concrete information have I gathered?\n",
    "    2. Gap assessment - What crucial information is still missing?\n",
    "    3. Quality evaluation - Do I have sufficient evidence/examples for a good answer?\n",
    "    4. Strategic decision - Should I continue searching or provide my answer?\n",
    "\n",
    "    Args:\n",
    "        reflection: Your detailed reflection on research progress, findings, gaps, and next steps\n",
    "\n",
    "    Returns:\n",
    "        Confirmation that reflection was recorded for decision-making\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df53163",
   "metadata": {},
   "source": [
    "### Research Instructions for SubAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa499159",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCHER_INSTRUCTIONS =\"\"\"You are a research assistant conducting research on the user's input topic. For context, today's date is       │\n",
    "│  {date}.                                                                                                        │\n",
    "│                                                                                                                 │\n",
    "│  <Task>                                                                                                         │\n",
    "│  Your job is to use tools to gather information about the user's input topic.                                   │\n",
    "│  You can use any of the tools provided to you to find resources that can help answer the research question.     │\n",
    "│  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          │\n",
    "│  </Task>                                                                                                        │\n",
    "│                                                                                                                 │\n",
    "│  <Available Tools>                                                                                              │\n",
    "│  You have access to two main tools:                                                                             │\n",
    "│  1. **tavily_search**: For conducting web searches to gather information                                        │\n",
    "│  2. **think_tool**: For reflection and strategic planning during research                                       │\n",
    "│                                                                                                                 │\n",
    "│  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       │\n",
    "│  </Available Tools>                                                                                             │\n",
    "│                                                                                                                 │\n",
    "│  <Instructions>                                                                                                 │\n",
    "│  Think like a human researcher with limited time. Follow these steps:                                           │\n",
    "│                                                                                                                 │\n",
    "│  1. **Read the question carefully** - What specific information does the user need?                             │\n",
    "│  2. **Start with broader searches** - Use broad, comprehensive queries first                                    │\n",
    "│  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 │\n",
    "│  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  │\n",
    "│  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              │\n",
    "│  </Instructions>                                                                                                │\n",
    "│                                                                                                                 │\n",
    "│  <Hard Limits>                                                                                                  │\n",
    "│  **Tool Call Budgets** (Prevent excessive searching):                                                           │\n",
    "│  - **Simple queries**: Use 1-2 search tool calls maximum                                                        │\n",
    "│  - **Normal queries**: Use 2-3 search tool calls maximum                                                        │\n",
    "│  - **Very Complex queries**: Use up to 5 search tool calls maximum                                              │\n",
    "│  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              │\n",
    "│                                                                                                                 │\n",
    "│  **Stop Immediately When**:                                                                                     │\n",
    "│  - You can answer the user's question comprehensively                                                           │\n",
    "│  - You have 3+ relevant examples/sources for the question                                                       │\n",
    "│  - Your last 2 searches returned similar information                                                            │\n",
    "│  </Hard Limits>                                                                                                 │\n",
    "│                                                                                                                 │\n",
    "│  <Show Your Thinking>                                                                                           │\n",
    "│  After each search tool call, use think_tool to analyze the results:                                            │\n",
    "│  - What key information did I find?                                                                             │\n",
    "│  - What's missing?                                                                                              │\n",
    "│  - Do I have enough to answer the question comprehensively?                                                     │\n",
    "│  - Should I search more or provide my answer?                                                                   │\n",
    "│  </Show Your Thinking>                                                                                          │\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d2cb1",
   "metadata": {},
   "source": [
    "## Deep Agent\n",
    "Now, we can just apply all of our prior learnings:\n",
    "\n",
    "- We'll give the researcher a `think_tool` and our `search_tool` above.\n",
    "- We'll give our parent agent file tools, a `think_tool`, and a `task` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PN\\AppData\\Local\\Temp\\ipykernel_15616\\832146826.py:34: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agents[_agent[\"name\"]] = create_react_agent(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Create agent using create_react_agent directly\n",
    "model = init_chat_model(model=\"openai:gpt-4o-mini\", api_key= \"sk-proj-***\", temperature=0.0)\n",
    "\n",
    "# Limits\n",
    "max_concurrent_research_units = 3\n",
    "max_researcher_iterations = 3\n",
    "\n",
    "# Tools\n",
    "sub_agent_tools = [tavily_search, think_tool]\n",
    "built_in_tools = [ls, read_file, write_file, write_todos, read_todos, think_tool]\n",
    "\n",
    "# Create research sub-agent\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=get_today_str()),\n",
    "    \"tools\": [\"tavily_search\", \"think_tool\"],\n",
    "}\n",
    "\n",
    "# Create task tool to delegate tasks to sub-agents\n",
    "task_tool = _create_task_tool(\n",
    "    sub_agent_tools, [research_sub_agent], model, DeepAgentState\n",
    ")\n",
    "\n",
    "delegation_tools = [task_tool]\n",
    "all_tools = sub_agent_tools + built_in_tools + delegation_tools  # search available to main agent for trivial cases\n",
    "\n",
    "# Build prompt\n",
    "SUBAGENT_INSTRUCTIONS = SUBAGENT_USAGE_INSTRUCTIONS.format(\n",
    "    max_concurrent_research_units=max_concurrent_research_units,\n",
    "    max_researcher_iterations=max_researcher_iterations,\n",
    "    date=get_today_str(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550b3f5",
   "metadata": {},
   "source": [
    "### All Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1198bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"# TODO MANAGEMENT\\n\"\n",
    "    + TODO_USAGE_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + \"# FILE SYSTEM USAGE\\n\"\n",
    "    + FILE_USAGE_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + \"# SUB-AGENT DELEGATION\\n\"\n",
    "    + SUBAGENT_USAGE_INSTRUCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0049741",
   "metadata": {},
   "source": [
    "### Creating and Drawing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d5e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PN\\AppData\\Local\\Temp\\ipykernel_15616\\3548560376.py:2: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create agent\n",
    "agent = create_react_agent(\n",
    "    model, all_tools, prompt=INSTRUCTIONS, state_schema=DeepAgentState\n",
    ")\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f25fd",
   "metadata": {},
   "source": [
    "### Invoke the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a8ce1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Give me an overview of Model Context Protocol (MCP).', additional_kwargs={}, response_metadata={}, id='8fd85ae0-411c-43bc-9cdb-11677639f180'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HLga6OJnr9EClSZGNeiufOsY', 'function': {'arguments': '{}', 'name': 'ls'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 2791, 'total_tokens': 2801, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWKteKd92JyW8jmaHhzBZlbj8VclP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--8d761e87-cbff-406b-9a2a-2ef1cf5e6214-0', tool_calls=[{'name': 'ls', 'args': {}, 'id': 'call_HLga6OJnr9EClSZGNeiufOsY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2791, 'output_tokens': 10, 'total_tokens': 2801, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=[], name='ls', id='d60da0c6-03a7-4c0c-9ce2-a2679aebbc5c', tool_call_id='call_HLga6OJnr9EClSZGNeiufOsY'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8WNDnszPKYJnG6Yv0b1hCP8p', 'function': {'arguments': '{\"file_path\":\"user_request.txt\",\"content\":\"Give me an overview of Model Context Protocol (MCP).\"}', 'name': 'write_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 2808, 'total_tokens': 2840, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWKtf8Tmqz5CkkhE1WX1c2DdBTVzZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--94ab0d9e-0280-487a-9f72-2fe7738a2133-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'user_request.txt', 'content': 'Give me an overview of Model Context Protocol (MCP).'}, 'id': 'call_8WNDnszPKYJnG6Yv0b1hCP8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2808, 'output_tokens': 32, 'total_tokens': 2840, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Updated file user_request.txt', name='write_file', id='dfe8f39c-bd57-4b34-a272-3b404ecdd98e', tool_call_id='call_8WNDnszPKYJnG6Yv0b1hCP8p'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_duUd4fB2pZHo9Edg0fq7DrCk', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP) overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 2853, 'total_tokens': 2876, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2688}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWKtiNrRqGdUiaC8EZqYyg9wDazvE', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a5d64b12-fd81-4577-b1e1-c4812d659001-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Model Context Protocol (MCP) overview'}, 'id': 'call_duUd4fB2pZHo9Edg0fq7DrCk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2853, 'output_tokens': 23, 'total_tokens': 2876, 'input_token_details': {'audio': 0, 'cache_read': 2688}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"🔍 Found 1 result(s) for 'Model Context Protocol (MCP) overview':\\n\\n- mcp_summary_bI5jb8qc.txt: The Model Context Protocol (MCP) is an open standard designed to connect large language model clients, like ChatGPT, to external tools and resources via an MCP server. This server facilitates interaction during conversations by exposing various tools that models can call upon, enabling them to produce results based on specified parameters and return supplementary metadata. The MCP framework ensures synchronization between the server, model, and user interface by standardizing the communication format, authentication mechanisms, and the handling of metadata. \\n\\nMCP's architecture includes capabilities to list available tools, execute calls to those tools based on user intent, and return structured content that can be rendered by the client interface. By standardizing on MCP, developers benefit from features such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility with multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers....\\n\\nFiles: mcp_summary_bI5jb8qc.txt\\n💡 Use read_file() to access full details when needed.\", name='tavily_search', id='caa17d80-5008-42ed-9ea8-e699ec03834b', tool_call_id='call_duUd4fB2pZHo9Edg0fq7DrCk'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IA71cjq5JK3tKeSRAYFd7rnt', 'function': {'arguments': '{\"file_path\":\"mcp_summary_bI5jb8qc.txt\"}', 'name': 'read_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 3133, 'total_tokens': 3157, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2816}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWKtqIzibwx1l6lTgVkZKQGG5Momh', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3f264ee4-2d34-416d-a5de-735b1ed95187-0', tool_calls=[{'name': 'read_file', 'args': {'file_path': 'mcp_summary_bI5jb8qc.txt'}, 'id': 'call_IA71cjq5JK3tKeSRAYFd7rnt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3133, 'output_tokens': 24, 'total_tokens': 3157, 'input_token_details': {'audio': 0, 'cache_read': 2816}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"     1\\t# Search Result: MCP - OpenAI Developers\\n     2\\t\\n     3\\t**URL:** https://developers.openai.com/apps-sdk/concepts/mcp-server/\\n     4\\t**Query:** Model Context Protocol (MCP) overview\\n     5\\t**Date:** Thu Oct 30, 2025\\n     6\\t\\n     7\\t## Summary\\n     8\\tThe Model Context Protocol (MCP) is an open standard designed to connect large language model clients, like ChatGPT, to external tools and resources via an MCP server. This server facilitates interaction during conversations by exposing various tools that models can call upon, enabling them to produce results based on specified parameters and return supplementary metadata. The MCP framework ensures synchronization between the server, model, and user interface by standardizing the communication format, authentication mechanisms, and the handling of metadata. \\n     9\\t\\n    10\\tMCP's architecture includes capabilities to list available tools, execute calls to those tools based on user intent, and return structured content that can be rendered by the client interface. By standardizing on MCP, developers benefit from features such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility with multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers.\\n    11\\t\\n    12\\t## Raw Content\\n    13\\t MCP\\n    14\\t  \\n    15\\t\\n    16\\t[![OpenAI Developers](/OpenAI_Developers.svg)](/)  \\n    17\\t\\n    18\\t[Resources](/)  [Codex](/codex)  [ChatGPT](/chatgpt)  [Blog](/blog)     Search ⌘K\\n    19\\t\\n    20\\tSearch the docs\\n    21\\t---------------\\n    22\\t\\n    23\\t⌘ K / Ctrl K\\n    24\\t\\n    25\\tClose\\n    26\\t\\n    27\\tPrimary navigation\\n    28\\t\\n    29\\tChatGPT     \\n    30\\t\\n    31\\tResources   Codex   ChatGPT   Blog\\n    32\\t\\n    33\\t1. [ChatGPT](/chatgpt)\\n    34\\t2. >\\n    35\\t     [Apps SDK](/apps-sdk)\\n    36\\t\\n    37\\t* [Home](/)\\n    38\\t\\n    39\\t### Categories\\n    40\\t\\n    41\\t* [Code](/resources/code)\\n    42\\t* [Cookbooks](/resources/cookbooks)\\n    43\\t* [Guides](/resources/guides)\\n    44\\t* [Videos](/resources/videos)\\n    45\\t\\n    46\\t### Topics\\n    47\\t\\n    48\\t* [Agents](/topics/agents)\\n    49\\t* [Audio & Voice](/topics/audio)\\n    50\\t* [Image generation](/topics/imagegen)\\n    51\\t* [Video generation](/topics/videogen)\\n    52\\t* [Tools](/topics/tools)\\n    53\\t* [Computer use](/topics/cua)\\n    54\\t* [Fine-tuning](/topics/fine-tuning)\\n    55\\t* [Scaling](/topics/scaling)\\n    56\\t\\n    57\\t* [Home](/codex)\\n    58\\t* [Quickstart](/codex/quickstart)\\n    59\\t* [Concepts](/codex/concepts)\\n    60\\t* [Pricing](/codex/pricing)\\n    61\\t* [Changelog](/codex/changelog)\\n    62\\t\\n    63\\t### Codex CLI\\n    64\\t\\n    65\\t* [Overview](/codex/cli)\\n    66\\t* [CLI Reference](/codex/cli/reference)\\n    67\\t* [Configuration](/codex/local-config#cli)\\n    68\\t\\n    69\\t### Codex IDE Extension\\n    70\\t\\n    71\\t* [Set up your IDE](/codex/ide)\\n    72\\t* [Configuration](/codex/local-config#ide)\\n    73\\t* [IDE → Cloud tasks](/codex/ide/cloud-tasks)\\n    74\\t\\n    75\\t### Codex Cloud\\n    76\\t\\n    77\\t* [Delegate to Codex](/codex/cloud)\\n    78\\t* [Environments](/codex/cloud/environments)\\n    79\\t* [Code Review](/codex/cloud/code-review)\\n    80\\t* [Internet Access](/codex/cloud/internet-access)\\n    81\\t\\n    82\\t### Codex SDK\\n    83\\t\\n    84\\t* [Overview](/codex/sdk)\\n    85\\t* [TypeScript](/codex/sdk#typescript-library)\\n    86\\t* [GitHub Action](/codex/sdk#github-action)\\n    87\\t\\n    88\\t### Guides\\n    89\\t\\n    90\\t* [Agents SDK](/codex/guides/agents-sdk)\\n    91\\t* [Prompting Codex](/codex/prompting)\\n    92\\t* [Model Context Protocol (MCP)](/codex/mcp)\\n    93\\t* [Autofix CI](/codex/autofix-ci)\\n    94\\t* [Enterprise Admin](/codex/enterprise)\\n    95\\t* [Security Admin](/codex/security)\\n    96\\t* [Codex on Windows](/codex/windows)\\n    97\\t\\n    98\\t### Integrations\\n    99\\t\\n   100\\t* [Slack](/codex/integrations/slack)\\n   101\\t\\n   102\\t### Resources\\n   103\\t\\n   104\\t* [AGENTS.md](https://agents.md)\\n   105\\t* [Codex on GitHub](https://github.com/openai/codex)\\n   106\\t\\n   107\\t* [Home](/apps-sdk)\\n   108\\t\\n   109\\t### Core Concepts\\n   110\\t\\n   111\\t* [MCP Server](/apps-sdk/concepts/mcp-server)\\n   112\\t* [User interaction](/apps-sdk/concepts/user-interaction)\\n   113\\t* [Design guidelines](/apps-sdk/concepts/design-guidelines)\\n   114\\t\\n   115\\t### Plan\\n   116\\t\\n   117\\t* [Research use cases](/apps-sdk/plan/use-case)\\n   118\\t* [Define tools](/apps-sdk/plan/tools)\\n   119\\t* [Design components](/apps-sdk/plan/components)\\n   120\\t\\n   121\\t### Build\\n   122\\t\\n   123\\t* [Set up your server](/apps-sdk/build/mcp-server)\\n   124\\t* [Build a custom UX](/apps-sdk/build/custom-ux)\\n   125\\t* [Authenticate users](/apps-sdk/build/auth)\\n   126\\t* [Persist state](/apps-sdk/build/storage)\\n   127\\t* [Examples](/apps-sdk/build/examples)\\n   128\\t\\n   129\\t### Deploy\\n   130\\t\\n   131\\t* [Deploy your app](/apps-sdk/deploy)\\n   132\\t* [Connect from ChatGPT](/apps-sdk/deploy/connect-chatgpt)\\n   133\\t* [Test your integration](/apps-sdk/deploy/testing)\\n   134\\t\\n   135\\t### Guides\\n   136\\t\\n   137\\t* [Optimize Metadata](/apps-sdk/guides/optimize-metadata)\\n   138\\t* [Security & Privacy](/apps-sdk/guides/security-privacy)\\n   139\\t* [Troubleshooting](/apps-sdk/deploy/troubleshooting)\\n   140\\t\\n   141\\t### Resources\\n   142\\t\\n   143\\t* [Reference](/apps-sdk/reference)\\n   144\\t* [App developer guidelines](/apps-sdk/app-developer-guidelines)\\n   145\\t\\n   146\\t* [All posts](/blog)\\n   147\\t\\n   148\\t### Recent\\n   149\\t\\n   150\\t* [Using Codex for education at Dagster Labs](/blog/codex-for-documentation-dagster)\\n   151\\t* [How Codex ran OpenAI DevDay 2025](/blog/codex-at-devday)\\n   152\\t* [Why we built the Responses API](/blog/responses-api)\\n   153\\t* [Developer notes on the Realtime API](/blog/realtime-api)\\n   154\\t* [Hello, world!](/blog/intro)\\n   155\\t\\n   156\\t1. [ChatGPT](/chatgpt)\\n   157\\t2. >\\n   158\\t   [Apps SDK](/apps-sdk)\\n   159\\t\\n   160\\t* [Home](/apps-sdk)\\n   161\\t\\n   162\\t### Core Concepts\\n   163\\t\\n   164\\t* [MCP Server](/apps-sdk/concepts/mcp-server)\\n   165\\t* [User interaction](/apps-sdk/concepts/user-interaction)\\n   166\\t* [Design guidelines](/apps-sdk/concepts/design-guidelines)\\n   167\\t\\n   168\\t### Plan\\n   169\\t\\n   170\\t* [Research use cases](/apps-sdk/plan/use-case)\\n   171\\t* [Define tools](/apps-sdk/plan/tools)\\n   172\\t* [Design components](/apps-sdk/plan/components)\\n   173\\t\\n   174\\t### Build\\n   175\\t\\n   176\\t* [Set up your server](/apps-sdk/build/mcp-server)\\n   177\\t* [Build a custom UX](/apps-sdk/build/custom-ux)\\n   178\\t* [Authenticate users](/apps-sdk/build/auth)\\n   179\\t* [Persist state](/apps-sdk/build/storage)\\n   180\\t* [Examples](/apps-sdk/build/examples)\\n   181\\t\\n   182\\t### Deploy\\n   183\\t\\n   184\\t* [Deploy your app](/apps-sdk/deploy)\\n   185\\t* [Connect from ChatGPT](/apps-sdk/deploy/connect-chatgpt)\\n   186\\t* [Test your integration](/apps-sdk/deploy/testing)\\n   187\\t\\n   188\\t### Guides\\n   189\\t\\n   190\\t* [Optimize Metadata](/apps-sdk/guides/optimize-metadata)\\n   191\\t* [Security & Privacy](/apps-sdk/guides/security-privacy)\\n   192\\t* [Troubleshooting](/apps-sdk/deploy/troubleshooting)\\n   193\\t\\n   194\\t### Resources\\n   195\\t\\n   196\\t* [Reference](/apps-sdk/reference)\\n   197\\t* [App developer guidelines](/apps-sdk/app-developer-guidelines)\\n   198\\t\\n   199\\t \\n   200\\t\\n   201\\tMCP\\n   202\\t===\\n   203\\t\\n   204\\tUnderstand how the Model Context Protocol works with Apps SDK.\\n   205\\t\\n   206\\tWhat is MCP?\\n   207\\t------------\\n   208\\t\\n   209\\tThe [Model Context Protocol](https://modelcontextprotocol.io/) (MCP) is an open specification for connecting large language model clients to external tools and resources. An MCP server exposes **tools** that a model can call during a conversation, and return results given specified parameters.\\n   210\\tOther resources (metadata) can be returned along with tool results, including the inline html that we can use in the Apps SDK to render an interface.\\n   211\\t\\n   212\\tWith Apps SDK, MCP is the backbone that keeps server, model, and UI in sync. By standardising the wire format, authentication, and metadata, it lets ChatGPT reason about your app the same way it reasons about built-in tools.\\n   213\\t\\n   214\\tProtocol building blocks\\n   215\\t------------------------\\n   216\\t\\n   217\\tA minimal MCP server for Apps SDK implements three capabilities:\\n   218\\t\\n   219\\t1. **List tools** – your server advertises the tools it supports, including their JSON Schema input and output contracts and optional annotations.\\n   220\\t2. **Call tools** – when a model selects a tool to use, it sends a `call_tool` request with the arguments corresponding to the user intent. Your server executes the action and returns structured content the model can parse.\\n   221\\t3. **Return components** – in addition to structured content returned by the tool, each tool (in its metadata) can optionally point to an [embedded resource](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#embedded-resources) that represents the interface to render in the ChatGPT client.\\n   222\\t\\n   223\\tThe protocol is transport agnostic, you can host the server over Server-Sent Events or Streamable HTTP. Apps SDK supports both options, but we recommend Streamable HTTP.\\n   224\\t\\n   225\\tWhy Apps SDK standardises on MCP\\n   226\\t--------------------------------\\n   227\\t\\n   228\\tWorking through MCP gives you several benefits out of the box:\\n   229\\t\\n   230\\t* **Discovery integration** – the model consumes your tool metadata and surface descriptions the same way it does for first-party connectors, enabling natural-language discovery and launcher ranking. See [Discovery](/apps-sdk/concepts/user-interaction) for details.\\n   231\\t* **Conversation awareness** – structured content and component state flow through the conversation. The model can inspect the JSON result, refer to IDs in follow-up turns, or render the component again later.\\n   232\\t* **Multiclient support** – MCP is self-describing, so your connector works across ChatGPT web and mobile without custom client code.\\n   233\\t* **Extensible auth** – the specification includes protected resource metadata, OAuth 2.1 flows, and dynamic client registration so you can control access without inventing a proprietary handshake.\\n   234\\t\\n   235\\tNext steps\\n   236\\t----------\\n   237\\t\\n   238\\tIf you’re new to MCP, we recommend starting with the following resources:\\n   239\\t\\n   240\\t* [Model Context Protocol specification](https://modelcontextprotocol.io/specification)\\n   241\\t* Official SDKs: [Python SDK (official; includes FastMCP module)](https://github.com/modelcontextprotocol/python-sdk) and [TypeScript](https://github.com/modelcontextprotocol/typescript-sdk)\\n   242\\t* [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for local debugging\\n   243\\t\\n   244\\tOnce you are comfortable with the MCP primitives, you can move on to the [Set up your server](/apps-sdk/build/mcp-server) guide for implementation details.\\n   245\\t\\n   246\\t[Next\\n   247\\t\\n   248\\tUser interaction](/apps-sdk/concepts/user-interaction)\\n   249\\t\\n   250\\t \", name='read_file', id='95fd76f5-83fb-434b-9703-d3ff53bf7f29', tool_call_id='call_IA71cjq5JK3tKeSRAYFd7rnt'),\n",
       " AIMessage(content=\"The Model Context Protocol (MCP) is an open standard designed to facilitate the connection between large language model clients, such as ChatGPT, and external tools and resources through an MCP server. This server enables interaction during conversations by exposing various tools that models can utilize, allowing them to generate results based on specified parameters and return additional metadata. The MCP framework standardizes communication formats, authentication mechanisms, and metadata handling, ensuring synchronization between the server, model, and user interface.\\n\\nMCP's architecture includes capabilities for listing available tools, executing calls to those tools based on user intent, and returning structured content that can be rendered by the client interface. By adopting MCP, developers gain advantages such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility across multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 187, 'prompt_tokens': 6385, 'total_tokens': 6572, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2816}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWKtshQyo2uPPsgmOmAvTMHxzBd2u', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--22d326ed-d4ec-4279-ab0a-1d816bc9a14b-0', usage_metadata={'input_tokens': 6385, 'output_tokens': 187, 'total_tokens': 6572, 'input_token_details': {'audio': 0, 'cache_read': 2816}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "result[\"messages\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7cb1a",
   "metadata": {},
   "source": [
    "### Pretty Print Function\n",
    "To better understand what the agent does and also see the workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd3eba",
   "metadata": {},
   "source": [
    "#### Func 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2090d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🤖 AGENT CONVERSATION LOG\n",
      "================================================================================\n",
      "\n",
      "📝 Message #1\n",
      "----------------------------------------\n",
      "Type: HumanMessage\n",
      "Content: Give me an overview of Model Context Protocol (MCP).\n",
      "\n",
      "\n",
      "📝 Message #2\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. ls - call_HLga6OJnr9EClSZGNeiufOsY\n",
      "Additional Info: {'tool_calls': [{'id': 'call_HLga6OJnr9EClSZGNeiufOsY', 'function': {'arguments': '{}', 'name': 'ls'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 2801 total\n",
      "  - Input: 2791\n",
      "  - Output: 10\n",
      "\n",
      "\n",
      "📝 Message #3\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "\n",
      "\n",
      "📝 Message #4\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. write_file - call_8WNDnszPKYJnG6Yv0b1hCP8p\n",
      "Additional Info: {'tool_calls': [{'id': 'call_8WNDnszPKYJnG6Yv0b1hCP8p', 'function': {'arguments': '{\"file_path\":\"user_request.txt\",\"content\":\"Give me an overview of Model Context Protocol (MCP).\"}', 'name': 'write_file'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 2840 total\n",
      "  - Input: 2808\n",
      "  - Output: 32\n",
      "\n",
      "\n",
      "📝 Message #5\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Updated file user_request.txt\n",
      "\n",
      "\n",
      "📝 Message #6\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. tavily_search - call_duUd4fB2pZHo9Edg0fq7DrCk\n",
      "Additional Info: {'tool_calls': [{'id': 'call_duUd4fB2pZHo9Edg0fq7DrCk', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP) overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 2876 total\n",
      "  - Input: 2853\n",
      "  - Output: 23\n",
      "\n",
      "\n",
      "📝 Message #7\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: 🔍 Found 1 result(s) for 'Model Context Protocol (MCP) overview':\n",
      "\n",
      "- mcp_summary_bI5jb8qc.txt: The Model Context Protocol (MCP) is an open standard designed to connect large language model clients, like ChatGPT, to external tools and resources via an MCP server. This server facilitates interaction during conversations by exposing various tools that models can call upon, enabling them to produce results based on specified parameters and return supplementary metadata. The MCP framework ensures synchronization between the server, model, and user interface by standardizing the communication format, authentication mechanisms, and the handling of metadata. \n",
      "\n",
      "MCP's architecture includes capabilities to list available tools, execute calls to those tools based on user intent, and return structured content that can be rendered by the client interface. By standardizing on MCP, developers benefit from features such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility with multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers....\n",
      "\n",
      "Files: mcp_summary_bI5jb8qc.txt\n",
      "💡 Use read_file() to access full details when needed.\n",
      "\n",
      "\n",
      "📝 Message #8\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. read_file - call_IA71cjq5JK3tKeSRAYFd7rnt\n",
      "Additional Info: {'tool_calls': [{'id': 'call_IA71cjq5JK3tKeSRAYFd7rnt', 'function': {'arguments': '{\"file_path\":\"mcp_summary_bI5jb8qc.txt\"}', 'name': 'read_file'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 3157 total\n",
      "  - Input: 3133\n",
      "  - Output: 24\n",
      "\n",
      "\n",
      "📝 Message #9\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content:      1\t# Search Result: MCP - OpenAI Developers\n",
      "     2\t\n",
      "     3\t**URL:** https://developers.openai.com/apps-sdk/concepts/mcp-server/\n",
      "     4\t**Query:** Model Context Protocol (MCP) overview\n",
      "     5\t**Date:** Thu Oct 30, 2025\n",
      "     6\t\n",
      "     7\t## Summary\n",
      "     8\tThe Model Context Protocol (MCP) is an open standard designed to connect large language model clients, like ChatGPT, to external tools and resources via an MCP server. This server facilitates interaction during conversations by exposing various tools that models can call upon, enabling them to produce results based on specified parameters and return supplementary metadata. The MCP framework ensures synchronization between the server, model, and user interface by standardizing the communication format, authentication mechanisms, and the handling of metadata. \n",
      "     9\t\n",
      "    10\tMCP's architecture includes capabilities to list available tools, execute calls to those tools based on user intent, and return structured content that can be rendered by the client interface. By standardizing on MCP, developers benefit from features such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility with multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers.\n",
      "    11\t\n",
      "    12\t## Raw Content\n",
      "    13\t MCP\n",
      "    14\t  \n",
      "    15\t\n",
      "    16\t[![OpenAI Developers](/OpenAI_Developers.svg)](/)  \n",
      "    17\t\n",
      "    18\t[Resources](/)  [Codex](/codex)  [ChatGPT](/chatgpt)  [Blog](/blog)     Search ⌘K\n",
      "    19\t\n",
      "    20\tSearch the docs\n",
      "    21\t---------------\n",
      "    22\t\n",
      "    23\t⌘ K / Ctrl K\n",
      "    24\t\n",
      "    25\tClose\n",
      "    26\t\n",
      "    27\tPrimary navigation\n",
      "    28\t\n",
      "    29\tChatGPT     \n",
      "    30\t\n",
      "    31\tResources   Codex   ChatGPT   Blog\n",
      "    32\t\n",
      "    33\t1. [ChatGPT](/chatgpt)\n",
      "    34\t2. >\n",
      "    35\t     [Apps SDK](/apps-sdk)\n",
      "    36\t\n",
      "    37\t* [Home](/)\n",
      "    38\t\n",
      "    39\t### Categories\n",
      "    40\t\n",
      "    41\t* [Code](/resources/code)\n",
      "    42\t* [Cookbooks](/resources/cookbooks)\n",
      "    43\t* [Guides](/resources/guides)\n",
      "    44\t* [Videos](/resources/videos)\n",
      "    45\t\n",
      "    46\t### Topics\n",
      "    47\t\n",
      "    48\t* [Agents](/topics/agents)\n",
      "    49\t* [Audio & Voice](/topics/audio)\n",
      "    50\t* [Image generation](/topics/imagegen)\n",
      "    51\t* [Video generation](/topics/videogen)\n",
      "    52\t* [Tools](/topics/tools)\n",
      "    53\t* [Computer use](/topics/cua)\n",
      "    54\t* [Fine-tuning](/topics/fine-tuning)\n",
      "    55\t* [Scaling](/topics/scaling)\n",
      "    56\t\n",
      "    57\t* [Home](/codex)\n",
      "    58\t* [Quickstart](/codex/quickstart)\n",
      "    59\t* [Concepts](/codex/concepts)\n",
      "    60\t* [Pricing](/codex/pricing)\n",
      "    61\t* [Changelog](/codex/changelog)\n",
      "    62\t\n",
      "    63\t### Codex CLI\n",
      "    64\t\n",
      "    65\t* [Overview](/codex/cli)\n",
      "    66\t* [CLI Reference](/codex/cli/reference)\n",
      "    67\t* [Configuration](/codex/local-config#cli)\n",
      "    68\t\n",
      "    69\t### Codex IDE Extension\n",
      "    70\t\n",
      "    71\t* [Set up your IDE](/codex/ide)\n",
      "    72\t* [Configuration](/codex/local-config#ide)\n",
      "    73\t* [IDE → Cloud tasks](/codex/ide/cloud-tasks)\n",
      "    74\t\n",
      "    75\t### Codex Cloud\n",
      "    76\t\n",
      "    77\t* [Delegate to Codex](/codex/cloud)\n",
      "    78\t* [Environments](/codex/cloud/environments)\n",
      "    79\t* [Code Review](/codex/cloud/code-review)\n",
      "    80\t* [Internet Access](/codex/cloud/internet-access)\n",
      "    81\t\n",
      "    82\t### Codex SDK\n",
      "    83\t\n",
      "    84\t* [Overview](/codex/sdk)\n",
      "    85\t* [TypeScript](/codex/sdk#typescript-library)\n",
      "    86\t* [GitHub Action](/codex/sdk#github-action)\n",
      "    87\t\n",
      "    88\t### Guides\n",
      "    89\t\n",
      "    90\t* [Agents SDK](/codex/guides/agents-sdk)\n",
      "    91\t* [Prompting Codex](/codex/prompting)\n",
      "    92\t* [Model Context Protocol (MCP)](/codex/mcp)\n",
      "    93\t* [Autofix CI](/codex/autofix-ci)\n",
      "    94\t* [Enterprise Admin](/codex/enterprise)\n",
      "    95\t* [Security Admin](/codex/security)\n",
      "    96\t* [Codex on Windows](/codex/windows)\n",
      "    97\t\n",
      "    98\t### Integrations\n",
      "    99\t\n",
      "   100\t* [Slack](/codex/integrations/slack)\n",
      "   101\t\n",
      "   102\t### Resources\n",
      "   103\t\n",
      "   104\t* [AGENTS.md](https://agents.md)\n",
      "   105\t* [Codex on GitHub](https://github.com/openai/codex)\n",
      "   106\t\n",
      "   107\t* [Home](/apps-sdk)\n",
      "   108\t\n",
      "   109\t### Core Concepts\n",
      "   110\t\n",
      "   111\t* [MCP Server](/apps-sdk/concepts/mcp-server)\n",
      "   112\t* [User interaction](/apps-sdk/concepts/user-interaction)\n",
      "   113\t* [Design guidelines](/apps-sdk/concepts/design-guidelines)\n",
      "   114\t\n",
      "   115\t### Plan\n",
      "   116\t\n",
      "   117\t* [Research use cases](/apps-sdk/plan/use-case)\n",
      "   118\t* [Define tools](/apps-sdk/plan/tools)\n",
      "   119\t* [Design components](/apps-sdk/plan/components)\n",
      "   120\t\n",
      "   121\t### Build\n",
      "   122\t\n",
      "   123\t* [Set up your server](/apps-sdk/build/mcp-server)\n",
      "   124\t* [Build a custom UX](/apps-sdk/build/custom-ux)\n",
      "   125\t* [Authenticate users](/apps-sdk/build/auth)\n",
      "   126\t* [Persist state](/apps-sdk/build/storage)\n",
      "   127\t* [Examples](/apps-sdk/build/examples)\n",
      "   128\t\n",
      "   129\t### Deploy\n",
      "   130\t\n",
      "   131\t* [Deploy your app](/apps-sdk/deploy)\n",
      "   132\t* [Connect from ChatGPT](/apps-sdk/deploy/connect-chatgpt)\n",
      "   133\t* [Test your integration](/apps-sdk/deploy/testing)\n",
      "   134\t\n",
      "   135\t### Guides\n",
      "   136\t\n",
      "   137\t* [Optimize Metadata](/apps-sdk/guides/optimize-metadata)\n",
      "   138\t* [Security & Privacy](/apps-sdk/guides/security-privacy)\n",
      "   139\t* [Troubleshooting](/apps-sdk/deploy/troubleshooting)\n",
      "   140\t\n",
      "   141\t### Resources\n",
      "   142\t\n",
      "   143\t* [Reference](/apps-sdk/reference)\n",
      "   144\t* [App developer guidelines](/apps-sdk/app-developer-guidelines)\n",
      "   145\t\n",
      "   146\t* [All posts](/blog)\n",
      "   147\t\n",
      "   148\t### Recent\n",
      "   149\t\n",
      "   150\t* [Using Codex for education at Dagster Labs](/blog/codex-for-documentation-dagster)\n",
      "   151\t* [How Codex ran OpenAI DevDay 2025](/blog/codex-at-devday)\n",
      "   152\t* [Why we built the Responses API](/blog/responses-api)\n",
      "   153\t* [Developer notes on the Realtime API](/blog/realtime-api)\n",
      "   154\t* [Hello, world!](/blog/intro)\n",
      "   155\t\n",
      "   156\t1. [ChatGPT](/chatgpt)\n",
      "   157\t2. >\n",
      "   158\t   [Apps SDK](/apps-sdk)\n",
      "   159\t\n",
      "   160\t* [Home](/apps-sdk)\n",
      "   161\t\n",
      "   162\t### Core Concepts\n",
      "   163\t\n",
      "   164\t* [MCP Server](/apps-sdk/concepts/mcp-server)\n",
      "   165\t* [User interaction](/apps-sdk/concepts/user-interaction)\n",
      "   166\t* [Design guidelines](/apps-sdk/concepts/design-guidelines)\n",
      "   167\t\n",
      "   168\t### Plan\n",
      "   169\t\n",
      "   170\t* [Research use cases](/apps-sdk/plan/use-case)\n",
      "   171\t* [Define tools](/apps-sdk/plan/tools)\n",
      "   172\t* [Design components](/apps-sdk/plan/components)\n",
      "   173\t\n",
      "   174\t### Build\n",
      "   175\t\n",
      "   176\t* [Set up your server](/apps-sdk/build/mcp-server)\n",
      "   177\t* [Build a custom UX](/apps-sdk/build/custom-ux)\n",
      "   178\t* [Authenticate users](/apps-sdk/build/auth)\n",
      "   179\t* [Persist state](/apps-sdk/build/storage)\n",
      "   180\t* [Examples](/apps-sdk/build/examples)\n",
      "   181\t\n",
      "   182\t### Deploy\n",
      "   183\t\n",
      "   184\t* [Deploy your app](/apps-sdk/deploy)\n",
      "   185\t* [Connect from ChatGPT](/apps-sdk/deploy/connect-chatgpt)\n",
      "   186\t* [Test your integration](/apps-sdk/deploy/testing)\n",
      "   187\t\n",
      "   188\t### Guides\n",
      "   189\t\n",
      "   190\t* [Optimize Metadata](/apps-sdk/guides/optimize-metadata)\n",
      "   191\t* [Security & Privacy](/apps-sdk/guides/security-privacy)\n",
      "   192\t* [Troubleshooting](/apps-sdk/deploy/troubleshooting)\n",
      "   193\t\n",
      "   194\t### Resources\n",
      "   195\t\n",
      "   196\t* [Reference](/apps-sdk/reference)\n",
      "   197\t* [App developer guidelines](/apps-sdk/app-developer-guidelines)\n",
      "   198\t\n",
      "   199\t \n",
      "   200\t\n",
      "   201\tMCP\n",
      "   202\t===\n",
      "   203\t\n",
      "   204\tUnderstand how the Model Context Protocol works with Apps SDK.\n",
      "   205\t\n",
      "   206\tWhat is MCP?\n",
      "   207\t------------\n",
      "   208\t\n",
      "   209\tThe [Model Context Protocol](https://modelcontextprotocol.io/) (MCP) is an open specification for connecting large language model clients to external tools and resources. An MCP server exposes **tools** that a model can call during a conversation, and return results given specified parameters.\n",
      "   210\tOther resources (metadata) can be returned along with tool results, including the inline html that we can use in the Apps SDK to render an interface.\n",
      "   211\t\n",
      "   212\tWith Apps SDK, MCP is the backbone that keeps server, model, and UI in sync. By standardising the wire format, authentication, and metadata, it lets ChatGPT reason about your app the same way it reasons about built-in tools.\n",
      "   213\t\n",
      "   214\tProtocol building blocks\n",
      "   215\t------------------------\n",
      "   216\t\n",
      "   217\tA minimal MCP server for Apps SDK implements three capabilities:\n",
      "   218\t\n",
      "   219\t1. **List tools** – your server advertises the tools it supports, including their JSON Schema input and output contracts and optional annotations.\n",
      "   220\t2. **Call tools** – when a model selects a tool to use, it sends a `call_tool` request with the arguments corresponding to the user intent. Your server executes the action and returns structured content the model can parse.\n",
      "   221\t3. **Return components** – in addition to structured content returned by the tool, each tool (in its metadata) can optionally point to an [embedded resource](https://modelcontextprotocol.io/specification/2025-06-18/server/tools#embedded-resources) that represents the interface to render in the ChatGPT client.\n",
      "   222\t\n",
      "   223\tThe protocol is transport agnostic, you can host the server over Server-Sent Events or Streamable HTTP. Apps SDK supports both options, but we recommend Streamable HTTP.\n",
      "   224\t\n",
      "   225\tWhy Apps SDK standardises on MCP\n",
      "   226\t--------------------------------\n",
      "   227\t\n",
      "   228\tWorking through MCP gives you several benefits out of the box:\n",
      "   229\t\n",
      "   230\t* **Discovery integration** – the model consumes your tool metadata and surface descriptions the same way it does for first-party connectors, enabling natural-language discovery and launcher ranking. See [Discovery](/apps-sdk/concepts/user-interaction) for details.\n",
      "   231\t* **Conversation awareness** – structured content and component state flow through the conversation. The model can inspect the JSON result, refer to IDs in follow-up turns, or render the component again later.\n",
      "   232\t* **Multiclient support** – MCP is self-describing, so your connector works across ChatGPT web and mobile without custom client code.\n",
      "   233\t* **Extensible auth** – the specification includes protected resource metadata, OAuth 2.1 flows, and dynamic client registration so you can control access without inventing a proprietary handshake.\n",
      "   234\t\n",
      "   235\tNext steps\n",
      "   236\t----------\n",
      "   237\t\n",
      "   238\tIf you’re new to MCP, we recommend starting with the following resources:\n",
      "   239\t\n",
      "   240\t* [Model Context Protocol specification](https://modelcontextprotocol.io/specification)\n",
      "   241\t* Official SDKs: [Python SDK (official; includes FastMCP module)](https://github.com/modelcontextprotocol/python-sdk) and [TypeScript](https://github.com/modelcontextprotocol/typescript-sdk)\n",
      "   242\t* [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for local debugging\n",
      "   243\t\n",
      "   244\tOnce you are comfortable with the MCP primitives, you can move on to the [Set up your server](/apps-sdk/build/mcp-server) guide for implementation details.\n",
      "   245\t\n",
      "   246\t[Next\n",
      "   247\t\n",
      "   248\tUser interaction](/apps-sdk/concepts/user-interaction)\n",
      "   249\t\n",
      "   250\t \n",
      "\n",
      "\n",
      "📝 Message #10\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Content: The Model Context Protocol (MCP) is an open standard designed to facilitate the connection between large language model clients, such as ChatGPT, and external tools and resources through an MCP server. This server enables interaction during conversations by exposing various tools that models can utilize, allowing them to generate results based on specified parameters and return additional metadata. The MCP framework standardizes communication formats, authentication mechanisms, and metadata handling, ensuring synchronization between the server, model, and user interface.\n",
      "\n",
      "MCP's architecture includes capabilities for listing available tools, executing calls to those tools based on user intent, and returning structured content that can be rendered by the client interface. By adopting MCP, developers gain advantages such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility across multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers.\n",
      "Additional Info: {'refusal': None}\n",
      "Token Usage: 6572 total\n",
      "  - Input: 6385\n",
      "  - Output: 187\n",
      "\n",
      "================================================================================\n",
      "✅ CONVERSATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    \"\"\"\n",
    "    Pretty print a conversation from an agent's message history.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message objects from agent.invoke() result\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🤖 AGENT CONVERSATION LOG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, message in enumerate(messages, 1):\n",
    "        print(f\"\\n📝 Message #{i}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get message type\n",
    "        msg_type = type(message).__name__\n",
    "        print(f\"Type: {msg_type}\")\n",
    "        \n",
    "        # Get role if available\n",
    "        if hasattr(message, 'role'):\n",
    "            print(f\"Role: {message.role}\")\n",
    "        \n",
    "        # Get content\n",
    "        if hasattr(message, 'content') and message.content:\n",
    "            content = message.content\n",
    "            if isinstance(content, str):\n",
    "                print(f\"Content: {content}\")\n",
    "            elif isinstance(content, list):\n",
    "                print(\"Content: [List of items]\")\n",
    "                for j, item in enumerate(content):\n",
    "                    print(f\"  {j+1}. {item}\")\n",
    "            else:\n",
    "                print(f\"Content: {content}\")\n",
    "        \n",
    "        # Get tool calls if available\n",
    "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "            print(f\"Tool Calls: {len(message.tool_calls)}\")\n",
    "            for j, tool_call in enumerate(message.tool_calls):\n",
    "                print(f\"  {j+1}. {tool_call.get('name', 'Unknown')} - {tool_call.get('id', 'No ID')}\")\n",
    "                if 'function' in tool_call and 'arguments' in tool_call['function']:\n",
    "                    args = tool_call['function']['arguments']\n",
    "                    print(f\"     Arguments: {args}\")\n",
    "        \n",
    "        # Get additional kwargs if available\n",
    "        if hasattr(message, 'additional_kwargs') and message.additional_kwargs:\n",
    "            print(f\"Additional Info: {message.additional_kwargs}\")\n",
    "        \n",
    "        # Get response metadata if available\n",
    "        if hasattr(message, 'response_metadata') and message.response_metadata:\n",
    "            metadata = message.response_metadata\n",
    "            if 'token_usage' in metadata:\n",
    "                tokens = metadata['token_usage']\n",
    "                print(f\"Token Usage: {tokens.get('total_tokens', 'N/A')} total\")\n",
    "                print(f\"  - Input: {tokens.get('prompt_tokens', 'N/A')}\")\n",
    "                print(f\"  - Output: {tokens.get('completion_tokens', 'N/A')}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"✅ CONVERSATION COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "pretty_print_conversation(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e3a08e",
   "metadata": {},
   "source": [
    "#### Func 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16086971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🤖 CONVERSATION TRACE\n",
      "================================================================================\n",
      "\n",
      "👤 **HUMAN** (Message #1)\n",
      "----------------------------------------\n",
      "📝 Give me an overview of Model Context Protocol (MCP).\n",
      "\n",
      "🤖 **ASSISTANT** (Message #2)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **ls**\n",
      "      Args: (none)\n",
      "📊 **Tokens:** Input: 2791 | Output: 10 | Total: 2801\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #3)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** ls\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** (empty)\n",
      "\n",
      "🤖 **ASSISTANT** (Message #4)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **write_file**\n",
      "      Args: {'file_path': 'user_request.txt', 'content': 'Give me an overview of Model Context Protocol (MCP).'}\n",
      "📊 **Tokens:** Input: 2808 | Output: 32 | Total: 2840\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #5)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** write_file\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** Updated file user_request.txt\n",
      "\n",
      "🤖 **ASSISTANT** (Message #6)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **tavily_search**\n",
      "      Args: {'query': 'Model Context Protocol (MCP) overview'}\n",
      "📊 **Tokens:** Input: 2853 | Output: 23 | Total: 2876\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #7)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** tavily_search\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** 🔍 Found 1 result(s) for 'Model Context Protocol (MCP) overview':\n",
      "\n",
      "- mcp_summary_bI5jb8qc.txt: The Model Context Protocol (MCP) is an open standard designed to connect large language model clients, lik...\n",
      "   📏 Full length: 1324 characters\n",
      "\n",
      "🤖 **ASSISTANT** (Message #8)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **read_file**\n",
      "      Args: {'file_path': 'mcp_summary_bI5jb8qc.txt'}\n",
      "📊 **Tokens:** Input: 3133 | Output: 24 | Total: 3157\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #9)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** read_file\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:**      1\t# Search Result: MCP - OpenAI Developers\n",
      "     2\t\n",
      "     3\t**URL:** https://developers.openai.com/apps-sdk/concepts/mcp-server/\n",
      "     4\t**Query:** Model Context Protocol (MCP) overview\n",
      "     5\t**Dat...\n",
      "   📏 Full length: 10893 characters\n",
      "\n",
      "🤖 **ASSISTANT** (Message #10)\n",
      "----------------------------------------\n",
      "💬 **Response:**\n",
      "   The Model Context Protocol (MCP) is an open standard designed to facilitate the connection between large language model clients, such as ChatGPT, and external tools and resources through an MCP server. This server enables interaction during conversations by exposing various tools that models can utilize, allowing them to generate results based on specified parameters and return additional metadata. The MCP framework standardizes communication formats, authentication mechanisms, and metadata handling, ensuring synchronization between the server, model, and user interface.\n",
      "\n",
      "MCP's architecture includes capabilities for listing available tools, executing calls to those tools based on user intent, and returning structured content that can be rendered by the client interface. By adopting MCP, developers gain advantages such as seamless tool discovery, enhanced conversation awareness through structured content flow, compatibility across multiple client platforms, and an extensible authentication framework. For further integration, developers are encouraged to consult the MCP specification and available SDKs to set up their own MCP servers.\n",
      "📊 **Tokens:** Input: 6385 | Output: 187 | Total: 6572\n",
      "\n",
      "================================================================================\n",
      "✅ END OF CONVERSATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    \"\"\"\n",
    "    Pretty print a conversation from LangChain messages with enhanced formatting.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of LangChain message objects (HumanMessage, AIMessage, ToolMessage)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🤖 CONVERSATION TRACE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, message in enumerate(messages, 1):\n",
    "        message_type = type(message).__name__\n",
    "        \n",
    "        # Human Message\n",
    "        if message_type == \"HumanMessage\":\n",
    "            print(f\"\\n👤 **HUMAN** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"📝 {message.content}\")\n",
    "            \n",
    "        # AI Message  \n",
    "        elif message_type == \"AIMessage\":\n",
    "            print(f\"\\n🤖 **ASSISTANT** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Check if there's text content\n",
    "            if message.content:\n",
    "                print(f\"💬 **Response:**\")\n",
    "                print(f\"   {message.content}\")\n",
    "            \n",
    "            # Check for tool calls\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                print(f\"🔧 **Tool Calls:**\")\n",
    "                for j, tool_call in enumerate(message.tool_calls, 1):\n",
    "                    print(f\"   {j}. **{tool_call['name']}**\")\n",
    "                    if tool_call['args']:\n",
    "                        print(f\"      Args: {tool_call['args']}\")\n",
    "                    else:\n",
    "                        print(f\"      Args: (none)\")\n",
    "            \n",
    "            # Token usage info\n",
    "            if hasattr(message, 'usage_metadata') and message.usage_metadata:\n",
    "                usage = message.usage_metadata\n",
    "                print(f\"📊 **Tokens:** Input: {usage.get('input_tokens', 'N/A')} | Output: {usage.get('output_tokens', 'N/A')} | Total: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "        # Tool Message\n",
    "        elif message_type == \"ToolMessage\":\n",
    "            print(f\"\\n⚙️ **TOOL RESULT** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"🔧 **Tool:** {message.name}\")\n",
    "            \n",
    "            # Check for errors\n",
    "            if hasattr(message, 'status') and message.status == 'error':\n",
    "                print(f\"❌ **Status:** ERROR\")\n",
    "                print(f\"💥 **Error:** {message.content}\")\n",
    "            else:\n",
    "                print(f\"✅ **Status:** SUCCESS\")\n",
    "                \n",
    "                # Format content based on length and type\n",
    "                content = str(message.content)\n",
    "                if len(content) > 200:\n",
    "                    print(f\"📄 **Result:** {content[:200]}...\")\n",
    "                    print(f\"   📏 Full length: {len(content)} characters\")\n",
    "                elif len(content) == 0 or content == \"[]\":\n",
    "                    print(f\"📄 **Result:** (empty)\")\n",
    "                else:\n",
    "                    print(f\"📄 **Result:** {content}\")\n",
    "        \n",
    "        # Unknown message type\n",
    "        else:\n",
    "            print(f\"\\n❓ **UNKNOWN MESSAGE TYPE: {message_type}** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"📄 Content: {getattr(message, 'content', 'No content')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✅ END OF CONVERSATION\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Usage example:\n",
    "pretty_print_conversation(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dbc74",
   "metadata": {},
   "source": [
    "## Using the Deep Agent Package\n",
    "**Now you understand the underlying patterns!**\n",
    "\n",
    "You can use the deepagents package as a simple abstraction:\n",
    "\n",
    "- It include the file system tools\n",
    "- It includes the todo tool\n",
    "- It includes the task tool\n",
    "\n",
    "You only need to supply the **sub-agent** and any **tools** you want the sub-agent to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1823e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=get_today_str()),\n",
    "    \"tools\": [tavily_search, think_tool],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b423b06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Notice**\n",
    "### Why did I bring up research_sub_agent again?\n",
    "\n",
    "\n",
    "**Bug:** `Documentation shows incorrect tool configuration format for subagents while use deepagents package`\n",
    "\n",
    "### Issue Description:\n",
    "\n",
    "#### Description\n",
    "The documentation contains incorrect code examples for configuring subagent tools. The example shows tool names as `strings` instead of actual tool `objects`, which causes a runtime error.\n",
    "\n",
    "#### Current Code\n",
    "```python\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=get_today_str()),\n",
    "    \"tools\": [\"tavily_search\", \"think_tool\"],  # ❌ WRONG: strings instead of objects\n",
    "}\n",
    "```\n",
    "\n",
    "#### Expected Code\n",
    "```python\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\", \n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=get_today_str()),\n",
    "    \"tools\": [tavily_search, think_tool],  # ✅ CORRECT: actual tool objects\n",
    "}\n",
    "```\n",
    "\n",
    "### Error Caused\n",
    "When using the documented approach, users get:\n",
    "\n",
    "`AttributeError: 'function' object has no attribute 'name'`\n",
    "\n",
    "\n",
    "### Additional Context\n",
    "The `tools` field expects actual tool objects (decorated with `@tool`), not string references to tool names. LangChain's `_ToolNode` requires tool objects with a `.name` attribute.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5c01db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\PN\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:504: UserWarning: typing.NotRequired is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepagents import create_deep_agent\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model =model,  \n",
    "    system_prompt=INSTRUCTIONS,\n",
    "    tools=sub_agent_tools,  \n",
    "    subagents=[research_sub_agent]\n",
    ")\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23e04250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Give me an very brief overview of Model Context Protocol (MCP).', additional_kwargs={}, response_metadata={}, id='f6a1243e-f471-4d28-94df-4eb84068e8f7'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6zE65Pgp54WzFyZGvKwgyvBq', 'function': {'arguments': '{}', 'name': 'ls'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 5644, 'total_tokens': 5654, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5504}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWL1AXoDw1lsCY43js1ud3JKlBZ0W', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--c9235970-46f9-4b4d-9c19-d6d3c4f6f106-0', tool_calls=[{'name': 'ls', 'args': {}, 'id': 'call_6zE65Pgp54WzFyZGvKwgyvBq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5644, 'output_tokens': 10, 'total_tokens': 5654, 'input_token_details': {'audio': 0, 'cache_read': 5504}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=[], name='ls', id='072ca1f5-e773-4bf5-ac5b-3d427d27136f', tool_call_id='call_6zE65Pgp54WzFyZGvKwgyvBq'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_muU6zcvnJhFlK4o9sUX9oc8K', 'function': {'arguments': '{\"file_path\":\"/user_request.txt\",\"content\":\"Give an overview of Model Context Protocol (MCP).\"}', 'name': 'write_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 5661, 'total_tokens': 5693, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5632}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1Btirpeg11GkakpCCd2gttYT1T', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--2ba04679-3e6f-4499-870e-6e70976b6b22-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': '/user_request.txt', 'content': 'Give an overview of Model Context Protocol (MCP).'}, 'id': 'call_muU6zcvnJhFlK4o9sUX9oc8K', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5661, 'output_tokens': 32, 'total_tokens': 5693, 'input_token_details': {'audio': 0, 'cache_read': 5632}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Updated file /user_request.txt', name='write_file', id='339497da-f0c8-4b5d-9f3a-58d946226c37', tool_call_id='call_muU6zcvnJhFlK4o9sUX9oc8K'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LXgvksdPnxQdZf9YUjpBzXfY', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP) overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 5707, 'total_tokens': 5730, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5632}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1D4ROHYpLGpP91VTNFtPghItj4', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--5bcff89a-cb32-4181-b70e-8231efb860f2-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Model Context Protocol (MCP) overview'}, 'id': 'call_LXgvksdPnxQdZf9YUjpBzXfY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5707, 'output_tokens': 23, 'total_tokens': 5730, 'input_token_details': {'audio': 0, 'cache_read': 5632}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP) overview'} with error:\\n state: Field required\\n Please fix the error and try again.\", name='tavily_search', id='1164727a-734e-44e7-9267-9e86a2958789', tool_call_id='call_LXgvksdPnxQdZf9YUjpBzXfY', status='error'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hOEsGRICq31dA79me50jpRSe', 'function': {'arguments': '{\"query\":\"Model Context Protocol MCP overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 5780, 'total_tokens': 5800, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5632}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1ERbQzea4bLtHXqkxBAXHkGOrs', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b5d5cd4e-96b5-49fc-b5fa-ad790f3d7ddd-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Model Context Protocol MCP overview'}, 'id': 'call_hOEsGRICq31dA79me50jpRSe', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5780, 'output_tokens': 20, 'total_tokens': 5800, 'input_token_details': {'audio': 0, 'cache_read': 5632}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol MCP overview'} with error:\\n state: Field required\\n Please fix the error and try again.\", name='tavily_search', id='97a8363c-249f-4ae4-98a0-5fa2937858fa', tool_call_id='call_hOEsGRICq31dA79me50jpRSe', status='error'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xInCefcdGG852LMREF83QKck', 'function': {'arguments': '{\"query\":\"Model Context Protocol\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 5847, 'total_tokens': 5865, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5760}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1Fd0KpVUL3HCBfNQrG40XiTbLl', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--03c615cb-8afa-49ac-8ebc-5163cbe454e1-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Model Context Protocol'}, 'id': 'call_xInCefcdGG852LMREF83QKck', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5847, 'output_tokens': 18, 'total_tokens': 5865, 'input_token_details': {'audio': 0, 'cache_read': 5760}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol'} with error:\\n state: Field required\\n Please fix the error and try again.\", name='tavily_search', id='be9df543-2af2-4106-9a23-db9634951189', tool_call_id='call_xInCefcdGG852LMREF83QKck', status='error'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Q5tdCHLEKjgTKA11GFoyN6Rl', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP)\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 5910, 'total_tokens': 5932, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5888}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1HiZE6NYDtYyZdE78TkwnwLVtG', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f13725df-95da-47e0-a474-39911ed74fea-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'Model Context Protocol (MCP)'}, 'id': 'call_Q5tdCHLEKjgTKA11GFoyN6Rl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5910, 'output_tokens': 22, 'total_tokens': 5932, 'input_token_details': {'audio': 0, 'cache_read': 5888}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP)'} with error:\\n state: Field required\\n Please fix the error and try again.\", name='tavily_search', id='e7b88983-ec39-40a7-a19d-e495c0a0373d', tool_call_id='call_Q5tdCHLEKjgTKA11GFoyN6Rl', status='error'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Fst4RMt8vIphw1vrTJCchoDu', 'function': {'arguments': '{\"description\":\"Research the Model Context Protocol (MCP) and provide a brief overview.\",\"subagent_type\":\"research-agent\"}', 'name': 'task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 5981, 'total_tokens': 6014, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5888}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CWL1IJTZIpNhm9X3KSwjnRGXbbCYp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--e063447f-051e-4a18-b71f-2d3a180ef3a6-0', tool_calls=[{'name': 'task', 'args': {'description': 'Research the Model Context Protocol (MCP) and provide a brief overview.', 'subagent_type': 'research-agent'}, 'id': 'call_Fst4RMt8vIphw1vrTJCchoDu', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5981, 'output_tokens': 33, 'total_tokens': 6014, 'input_token_details': {'audio': 0, 'cache_read': 5888}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='The Model Context Protocol (MCP) is a framework designed to facilitate the integration and interoperability of various models within a system. It provides a structured approach to managing the context in which models operate, ensuring that they can effectively communicate and share information. Here are some key points about the MCP:\\n\\n1. **Purpose**: The MCP aims to standardize how models interact with each other and with the data they use. This is particularly important in complex systems where multiple models may need to work together, such as in simulations, data analysis, and decision-making processes.\\n\\n2. **Components**: The protocol typically includes specifications for data formats, communication methods, and context management. This allows models to understand the environment in which they are operating and to adapt their behavior accordingly.\\n\\n3. **Applications**: MCP can be applied in various fields, including artificial intelligence, systems engineering, and data science. It is particularly useful in scenarios where models need to be updated or modified dynamically based on changing conditions or new information.\\n\\n4. **Benefits**: By using the MCP, organizations can improve the efficiency and effectiveness of their modeling efforts. It helps reduce redundancy, enhances collaboration between different models, and ensures that all components of a system are aligned in their objectives.\\n\\n5. **Challenges**: Implementing the MCP may require significant changes to existing systems and processes. Organizations must ensure that all stakeholders are on board and that the necessary infrastructure is in place to support the protocol.\\n\\nIf you need more specific details or examples related to the Model Context Protocol, please let me know!', name='task', id='ad40be81-98b5-4ea0-b498-1fffe4ed64d8', tool_call_id='call_Fst4RMt8vIphw1vrTJCchoDu'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dcfbgUwijECKKGAPSYn0X2HR', 'function': {'arguments': '{\"file_path\":\"/user_request.txt\"}', 'name': 'read_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 6332, 'total_tokens': 6350, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 5888}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1kFrwp2sOItiVOirDKralrGkN9', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3d24f240-cc73-4379-ae56-7eae09f02711-0', tool_calls=[{'name': 'read_file', 'args': {'file_path': '/user_request.txt'}, 'id': 'call_dcfbgUwijECKKGAPSYn0X2HR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6332, 'output_tokens': 18, 'total_tokens': 6350, 'input_token_details': {'audio': 0, 'cache_read': 5888}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='     1\\tGive an overview of Model Context Protocol (MCP).', name='read_file', id='c99d1ab1-172f-4e14-965b-8bb2ff46c722', tool_call_id='call_dcfbgUwijECKKGAPSYn0X2HR'),\n",
       " AIMessage(content='The Model Context Protocol (MCP) is a framework designed to enhance the integration and interoperability of various models within a system. Its primary purpose is to standardize interactions among models and the data they utilize, which is crucial in complex systems where multiple models must collaborate, such as in simulations and decision-making processes.\\n\\nKey components of MCP include specifications for data formats, communication methods, and context management, enabling models to understand their operational environment and adapt accordingly. Applications of MCP span fields like artificial intelligence and data science, where it improves modeling efficiency and collaboration while aligning system components. However, implementing MCP may pose challenges, requiring significant adjustments to existing systems and stakeholder engagement.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 6373, 'total_tokens': 6506, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6272}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CWL1lnhKBE1wKNQ8aNmOTycNmO2DR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--395448db-078a-4e52-b4fd-c5e64aff52df-0', usage_metadata={'input_tokens': 6373, 'output_tokens': 133, 'total_tokens': 6506, 'input_token_details': {'audio': 0, 'cache_read': 6272}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an very brief overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f1851",
   "metadata": {},
   "source": [
    "### Pretty Print Function\n",
    "To better understand what the agent does and also see the workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db39dd",
   "metadata": {},
   "source": [
    "#### Func 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b9ac174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🤖 AGENT CONVERSATION LOG\n",
      "================================================================================\n",
      "\n",
      "📝 Message #1\n",
      "----------------------------------------\n",
      "Type: HumanMessage\n",
      "Content: Give me an very brief overview of Model Context Protocol (MCP).\n",
      "\n",
      "\n",
      "📝 Message #2\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. ls - call_6zE65Pgp54WzFyZGvKwgyvBq\n",
      "Additional Info: {'tool_calls': [{'id': 'call_6zE65Pgp54WzFyZGvKwgyvBq', 'function': {'arguments': '{}', 'name': 'ls'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5654 total\n",
      "  - Input: 5644\n",
      "  - Output: 10\n",
      "\n",
      "\n",
      "📝 Message #3\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "\n",
      "\n",
      "📝 Message #4\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. write_file - call_muU6zcvnJhFlK4o9sUX9oc8K\n",
      "Additional Info: {'tool_calls': [{'id': 'call_muU6zcvnJhFlK4o9sUX9oc8K', 'function': {'arguments': '{\"file_path\":\"/user_request.txt\",\"content\":\"Give an overview of Model Context Protocol (MCP).\"}', 'name': 'write_file'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5693 total\n",
      "  - Input: 5661\n",
      "  - Output: 32\n",
      "\n",
      "\n",
      "📝 Message #5\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Updated file /user_request.txt\n",
      "\n",
      "\n",
      "📝 Message #6\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. tavily_search - call_LXgvksdPnxQdZf9YUjpBzXfY\n",
      "Additional Info: {'tool_calls': [{'id': 'call_LXgvksdPnxQdZf9YUjpBzXfY', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP) overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5730 total\n",
      "  - Input: 5707\n",
      "  - Output: 23\n",
      "\n",
      "\n",
      "📝 Message #7\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP) overview'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "\n",
      "📝 Message #8\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. tavily_search - call_hOEsGRICq31dA79me50jpRSe\n",
      "Additional Info: {'tool_calls': [{'id': 'call_hOEsGRICq31dA79me50jpRSe', 'function': {'arguments': '{\"query\":\"Model Context Protocol MCP overview\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5800 total\n",
      "  - Input: 5780\n",
      "  - Output: 20\n",
      "\n",
      "\n",
      "📝 Message #9\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol MCP overview'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "\n",
      "📝 Message #10\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. tavily_search - call_xInCefcdGG852LMREF83QKck\n",
      "Additional Info: {'tool_calls': [{'id': 'call_xInCefcdGG852LMREF83QKck', 'function': {'arguments': '{\"query\":\"Model Context Protocol\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5865 total\n",
      "  - Input: 5847\n",
      "  - Output: 18\n",
      "\n",
      "\n",
      "📝 Message #11\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "\n",
      "📝 Message #12\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. tavily_search - call_Q5tdCHLEKjgTKA11GFoyN6Rl\n",
      "Additional Info: {'tool_calls': [{'id': 'call_Q5tdCHLEKjgTKA11GFoyN6Rl', 'function': {'arguments': '{\"query\":\"Model Context Protocol (MCP)\"}', 'name': 'tavily_search'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 5932 total\n",
      "  - Input: 5910\n",
      "  - Output: 22\n",
      "\n",
      "\n",
      "📝 Message #13\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP)'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "\n",
      "📝 Message #14\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. task - call_Fst4RMt8vIphw1vrTJCchoDu\n",
      "Additional Info: {'tool_calls': [{'id': 'call_Fst4RMt8vIphw1vrTJCchoDu', 'function': {'arguments': '{\"description\":\"Research the Model Context Protocol (MCP) and provide a brief overview.\",\"subagent_type\":\"research-agent\"}', 'name': 'task'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 6014 total\n",
      "  - Input: 5981\n",
      "  - Output: 33\n",
      "\n",
      "\n",
      "📝 Message #15\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content: The Model Context Protocol (MCP) is a framework designed to facilitate the integration and interoperability of various models within a system. It provides a structured approach to managing the context in which models operate, ensuring that they can effectively communicate and share information. Here are some key points about the MCP:\n",
      "\n",
      "1. **Purpose**: The MCP aims to standardize how models interact with each other and with the data they use. This is particularly important in complex systems where multiple models may need to work together, such as in simulations, data analysis, and decision-making processes.\n",
      "\n",
      "2. **Components**: The protocol typically includes specifications for data formats, communication methods, and context management. This allows models to understand the environment in which they are operating and to adapt their behavior accordingly.\n",
      "\n",
      "3. **Applications**: MCP can be applied in various fields, including artificial intelligence, systems engineering, and data science. It is particularly useful in scenarios where models need to be updated or modified dynamically based on changing conditions or new information.\n",
      "\n",
      "4. **Benefits**: By using the MCP, organizations can improve the efficiency and effectiveness of their modeling efforts. It helps reduce redundancy, enhances collaboration between different models, and ensures that all components of a system are aligned in their objectives.\n",
      "\n",
      "5. **Challenges**: Implementing the MCP may require significant changes to existing systems and processes. Organizations must ensure that all stakeholders are on board and that the necessary infrastructure is in place to support the protocol.\n",
      "\n",
      "If you need more specific details or examples related to the Model Context Protocol, please let me know!\n",
      "\n",
      "\n",
      "📝 Message #16\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Tool Calls: 1\n",
      "  1. read_file - call_dcfbgUwijECKKGAPSYn0X2HR\n",
      "Additional Info: {'tool_calls': [{'id': 'call_dcfbgUwijECKKGAPSYn0X2HR', 'function': {'arguments': '{\"file_path\":\"/user_request.txt\"}', 'name': 'read_file'}, 'type': 'function'}], 'refusal': None}\n",
      "Token Usage: 6350 total\n",
      "  - Input: 6332\n",
      "  - Output: 18\n",
      "\n",
      "\n",
      "📝 Message #17\n",
      "----------------------------------------\n",
      "Type: ToolMessage\n",
      "Content:      1\tGive an overview of Model Context Protocol (MCP).\n",
      "\n",
      "\n",
      "📝 Message #18\n",
      "----------------------------------------\n",
      "Type: AIMessage\n",
      "Content: The Model Context Protocol (MCP) is a framework designed to enhance the integration and interoperability of various models within a system. Its primary purpose is to standardize interactions among models and the data they utilize, which is crucial in complex systems where multiple models must collaborate, such as in simulations and decision-making processes.\n",
      "\n",
      "Key components of MCP include specifications for data formats, communication methods, and context management, enabling models to understand their operational environment and adapt accordingly. Applications of MCP span fields like artificial intelligence and data science, where it improves modeling efficiency and collaboration while aligning system components. However, implementing MCP may pose challenges, requiring significant adjustments to existing systems and stakeholder engagement.\n",
      "Additional Info: {'refusal': None}\n",
      "Token Usage: 6506 total\n",
      "  - Input: 6373\n",
      "  - Output: 133\n",
      "\n",
      "================================================================================\n",
      "✅ CONVERSATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    \"\"\"\n",
    "    Pretty print a conversation from an agent's message history.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message objects from agent.invoke() result\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🤖 AGENT CONVERSATION LOG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, message in enumerate(messages, 1):\n",
    "        print(f\"\\n📝 Message #{i}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get message type\n",
    "        msg_type = type(message).__name__\n",
    "        print(f\"Type: {msg_type}\")\n",
    "        \n",
    "        # Get role if available\n",
    "        if hasattr(message, 'role'):\n",
    "            print(f\"Role: {message.role}\")\n",
    "        \n",
    "        # Get content\n",
    "        if hasattr(message, 'content') and message.content:\n",
    "            content = message.content\n",
    "            if isinstance(content, str):\n",
    "                print(f\"Content: {content}\")\n",
    "            elif isinstance(content, list):\n",
    "                print(\"Content: [List of items]\")\n",
    "                for j, item in enumerate(content):\n",
    "                    print(f\"  {j+1}. {item}\")\n",
    "            else:\n",
    "                print(f\"Content: {content}\")\n",
    "        \n",
    "        # Get tool calls if available\n",
    "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "            print(f\"Tool Calls: {len(message.tool_calls)}\")\n",
    "            for j, tool_call in enumerate(message.tool_calls):\n",
    "                print(f\"  {j+1}. {tool_call.get('name', 'Unknown')} - {tool_call.get('id', 'No ID')}\")\n",
    "                if 'function' in tool_call and 'arguments' in tool_call['function']:\n",
    "                    args = tool_call['function']['arguments']\n",
    "                    print(f\"     Arguments: {args}\")\n",
    "        \n",
    "        # Get additional kwargs if available\n",
    "        if hasattr(message, 'additional_kwargs') and message.additional_kwargs:\n",
    "            print(f\"Additional Info: {message.additional_kwargs}\")\n",
    "        \n",
    "        # Get response metadata if available\n",
    "        if hasattr(message, 'response_metadata') and message.response_metadata:\n",
    "            metadata = message.response_metadata\n",
    "            if 'token_usage' in metadata:\n",
    "                tokens = metadata['token_usage']\n",
    "                print(f\"Token Usage: {tokens.get('total_tokens', 'N/A')} total\")\n",
    "                print(f\"  - Input: {tokens.get('prompt_tokens', 'N/A')}\")\n",
    "                print(f\"  - Output: {tokens.get('completion_tokens', 'N/A')}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"✅ CONVERSATION COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "pretty_print_conversation(result[\"messages\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba98548",
   "metadata": {},
   "source": [
    "#### Func 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf125c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🤖 CONVERSATION TRACE\n",
      "================================================================================\n",
      "\n",
      "👤 **HUMAN** (Message #1)\n",
      "----------------------------------------\n",
      "📝 Give me an very brief overview of Model Context Protocol (MCP).\n",
      "\n",
      "🤖 **ASSISTANT** (Message #2)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **ls**\n",
      "      Args: (none)\n",
      "📊 **Tokens:** Input: 5644 | Output: 10 | Total: 5654\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #3)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** ls\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** (empty)\n",
      "\n",
      "🤖 **ASSISTANT** (Message #4)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **write_file**\n",
      "      Args: {'file_path': '/user_request.txt', 'content': 'Give an overview of Model Context Protocol (MCP).'}\n",
      "📊 **Tokens:** Input: 5661 | Output: 32 | Total: 5693\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #5)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** write_file\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** Updated file /user_request.txt\n",
      "\n",
      "🤖 **ASSISTANT** (Message #6)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **tavily_search**\n",
      "      Args: {'query': 'Model Context Protocol (MCP) overview'}\n",
      "📊 **Tokens:** Input: 5707 | Output: 23 | Total: 5730\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #7)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** tavily_search\n",
      "❌ **Status:** ERROR\n",
      "💥 **Error:** Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP) overview'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "🤖 **ASSISTANT** (Message #8)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **tavily_search**\n",
      "      Args: {'query': 'Model Context Protocol MCP overview'}\n",
      "📊 **Tokens:** Input: 5780 | Output: 20 | Total: 5800\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #9)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** tavily_search\n",
      "❌ **Status:** ERROR\n",
      "💥 **Error:** Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol MCP overview'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "🤖 **ASSISTANT** (Message #10)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **tavily_search**\n",
      "      Args: {'query': 'Model Context Protocol'}\n",
      "📊 **Tokens:** Input: 5847 | Output: 18 | Total: 5865\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #11)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** tavily_search\n",
      "❌ **Status:** ERROR\n",
      "💥 **Error:** Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "🤖 **ASSISTANT** (Message #12)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **tavily_search**\n",
      "      Args: {'query': 'Model Context Protocol (MCP)'}\n",
      "📊 **Tokens:** Input: 5910 | Output: 22 | Total: 5932\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #13)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** tavily_search\n",
      "❌ **Status:** ERROR\n",
      "💥 **Error:** Error invoking tool 'tavily_search' with kwargs {'query': 'Model Context Protocol (MCP)'} with error:\n",
      " state: Field required\n",
      " Please fix the error and try again.\n",
      "\n",
      "🤖 **ASSISTANT** (Message #14)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **task**\n",
      "      Args: {'description': 'Research the Model Context Protocol (MCP) and provide a brief overview.', 'subagent_type': 'research-agent'}\n",
      "📊 **Tokens:** Input: 5981 | Output: 33 | Total: 6014\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #15)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** task\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:** The Model Context Protocol (MCP) is a framework designed to facilitate the integration and interoperability of various models within a system. It provides a structured approach to managing the context...\n",
      "   📏 Full length: 1767 characters\n",
      "\n",
      "🤖 **ASSISTANT** (Message #16)\n",
      "----------------------------------------\n",
      "🔧 **Tool Calls:**\n",
      "   1. **read_file**\n",
      "      Args: {'file_path': '/user_request.txt'}\n",
      "📊 **Tokens:** Input: 6332 | Output: 18 | Total: 6350\n",
      "\n",
      "⚙️ **TOOL RESULT** (Message #17)\n",
      "----------------------------------------\n",
      "🔧 **Tool:** read_file\n",
      "✅ **Status:** SUCCESS\n",
      "📄 **Result:**      1\tGive an overview of Model Context Protocol (MCP).\n",
      "\n",
      "🤖 **ASSISTANT** (Message #18)\n",
      "----------------------------------------\n",
      "💬 **Response:**\n",
      "   The Model Context Protocol (MCP) is a framework designed to enhance the integration and interoperability of various models within a system. Its primary purpose is to standardize interactions among models and the data they utilize, which is crucial in complex systems where multiple models must collaborate, such as in simulations and decision-making processes.\n",
      "\n",
      "Key components of MCP include specifications for data formats, communication methods, and context management, enabling models to understand their operational environment and adapt accordingly. Applications of MCP span fields like artificial intelligence and data science, where it improves modeling efficiency and collaboration while aligning system components. However, implementing MCP may pose challenges, requiring significant adjustments to existing systems and stakeholder engagement.\n",
      "📊 **Tokens:** Input: 6373 | Output: 133 | Total: 6506\n",
      "\n",
      "================================================================================\n",
      "✅ END OF CONVERSATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    \"\"\"\n",
    "    Pretty print a conversation from LangChain messages with enhanced formatting.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of LangChain message objects (HumanMessage, AIMessage, ToolMessage)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🤖 CONVERSATION TRACE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, message in enumerate(messages, 1):\n",
    "        message_type = type(message).__name__\n",
    "        \n",
    "        # Human Message\n",
    "        if message_type == \"HumanMessage\":\n",
    "            print(f\"\\n👤 **HUMAN** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"📝 {message.content}\")\n",
    "            \n",
    "        # AI Message  \n",
    "        elif message_type == \"AIMessage\":\n",
    "            print(f\"\\n🤖 **ASSISTANT** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Check if there's text content\n",
    "            if message.content:\n",
    "                print(f\"💬 **Response:**\")\n",
    "                print(f\"   {message.content}\")\n",
    "            \n",
    "            # Check for tool calls\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                print(f\"🔧 **Tool Calls:**\")\n",
    "                for j, tool_call in enumerate(message.tool_calls, 1):\n",
    "                    print(f\"   {j}. **{tool_call['name']}**\")\n",
    "                    if tool_call['args']:\n",
    "                        print(f\"      Args: {tool_call['args']}\")\n",
    "                    else:\n",
    "                        print(f\"      Args: (none)\")\n",
    "            \n",
    "            # Token usage info\n",
    "            if hasattr(message, 'usage_metadata') and message.usage_metadata:\n",
    "                usage = message.usage_metadata\n",
    "                print(f\"📊 **Tokens:** Input: {usage.get('input_tokens', 'N/A')} | Output: {usage.get('output_tokens', 'N/A')} | Total: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "        # Tool Message\n",
    "        elif message_type == \"ToolMessage\":\n",
    "            print(f\"\\n⚙️ **TOOL RESULT** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"🔧 **Tool:** {message.name}\")\n",
    "            \n",
    "            # Check for errors\n",
    "            if hasattr(message, 'status') and message.status == 'error':\n",
    "                print(f\"❌ **Status:** ERROR\")\n",
    "                print(f\"💥 **Error:** {message.content}\")\n",
    "            else:\n",
    "                print(f\"✅ **Status:** SUCCESS\")\n",
    "                \n",
    "                # Format content based on length and type\n",
    "                content = str(message.content)\n",
    "                if len(content) > 200:\n",
    "                    print(f\"📄 **Result:** {content[:200]}...\")\n",
    "                    print(f\"   📏 Full length: {len(content)} characters\")\n",
    "                elif len(content) == 0 or content == \"[]\":\n",
    "                    print(f\"📄 **Result:** (empty)\")\n",
    "                else:\n",
    "                    print(f\"📄 **Result:** {content}\")\n",
    "        \n",
    "        # Unknown message type\n",
    "        else:\n",
    "            print(f\"\\n❓ **UNKNOWN MESSAGE TYPE: {message_type}** (Message #{i})\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"📄 Content: {getattr(message, 'content', 'No content')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✅ END OF CONVERSATION\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Usage example:\n",
    "pretty_print_conversation(result[\"messages\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
