{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8f02d7",
   "metadata": {},
   "source": [
    "This document is number `1 of 5` documents I have written, based on the `LangChain Academy Deep Agents with LangGraph` course.\n",
    "\n",
    "The course itself has repositories that it provides you with. If my documents are not useful to you, I suggest you check them out.\n",
    "\n",
    "There are now several successful examples of very **capable** and **long-running** agents. They have given these agents the \n",
    "name `“Deep Agents”` because they believe that they are completely different from previous generations of agents. In \n",
    "this course, you will learn what makes them different and build your own Deep Agent.\n",
    "\n",
    "In LangChain, a Deep Agent is built that is simple and configurable, allowing users to build long-running agents quickly and easily.\n",
    "\n",
    "In this course, you will build a **Deep Research Agent** using Deep Agent. The course is divided into seven modules.\n",
    "\n",
    "Each module includes a video lesson that introduces you to the key concepts, along with related workbooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffcad6",
   "metadata": {},
   "source": [
    "This document walks you through creating a **ReAct** *(Reasoning and Acting)* AI agent using LangGraph’s prebuilt abstractions. The goal is to provide clear explanations and code examples so that even readers new to LangGraph can follow along and fully understand how it works.\n",
    "\n",
    "LangGraph is a library for building `“graph-based”` AI workflows. The [prebuilt React agent](https://python.langchain.com/en/latest/modules/langchain/index.html#langgraph.prebuilt.create_react_agent) abstraction makes it easy to create an agent that reasons step-by-step (chain-of-thought) and calls external tools when needed. \n",
    "\n",
    "In this document, we’ll:\n",
    "\n",
    "- Explain the ReAct framework and agent components\n",
    "\n",
    "- Show how to define tools that the agent can call\n",
    "\n",
    "- Build and invoke a ReAct agent with a calculator tool\n",
    "\n",
    "- Examine how the agent’s graph, state, and messaging loop work\n",
    "\n",
    "- Access and modify agent state inside tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f6af8",
   "metadata": {},
   "source": [
    "#### What is a ReAct Agent?\n",
    "A ReAct agent combines **chain-of-thought reasoning** **(CoT)** with the ability to call external tools during the reasoning process. It operates in a loop:\n",
    "\n",
    "- **LLM Thinks:** The language model (LLM) reviews its system prompt, the conversation history, and information about available tools.\n",
    "\n",
    "- **Decide to Act:** The LLM decides if a tool is needed to answer the question or help reasoning. If so, it selects a tool and provides the arguments for that tool in a special `“tool call.”`\n",
    "\n",
    "- **Call Tools:** The agent framework detects the tool call, executes the corresponding tool (e.g., a calculator, search engine, or any custom function), and returns the result.\n",
    "\n",
    "- **Observe and Continue:** The LLM sees the tool’s output (the observation), incorporates it into its reasoning, and either calls another tool or generates a final answer.\n",
    "\n",
    "- **Loop Ends:** When the LLM no longer needs any more tools, it produces a final response to the user.\n",
    "\n",
    "The LangGraph `create_react_agent` function automates this loop. You provide an LLM (via LangChain), one or more tools (functions decorated with `@tool`), and an optional system prompt. Under the hood, LangGraph builds a state graph with nodes for the LLM and tool executions, handling the message flow, state updates, and stopping conditions for you.\n",
    "\n",
    "#### Key Features of LangGraph’s Prebuilt Agent\n",
    "\n",
    "The `create_react_agent` abstraction offers many advanced features (we won’t use all of them in this simple example, but they’re worth knowing):\n",
    "\n",
    "- **Memory:** You can enable *short-term* or *long-term* memory to make the agent’s behavior stateful across turns or sessions.\n",
    "\n",
    "- **Human-in-the-loop:** The agent can pause for human feedback or approval between steps.\n",
    "\n",
    "- **Streaming:** Support for streaming tokens and tool outputs in real time.\n",
    "\n",
    "- **Traces:** Integrates with LangSmith to trace and debug the agent’s execution.\n",
    "\n",
    "- **Structured Output:** Define a schema for the final response, and LangGraph can enforce and output structured `JSON`.\n",
    "\n",
    "In this document, we’ll use the “simple” agent format without hooks or structured outputs, just to focus on the core mechanism. We will, however, demonstrate how to manage custom state and look at how tool calls work in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67959ed7",
   "metadata": {},
   "source": [
    "#### Defining a Tool\n",
    "Agents become truly powerful when they can call tools—special functions that do tasks like *calculations*, *web searches*, *database queries*, etc. For this example, we’ll create a simple **calculator tool**.\n",
    "\n",
    "Using LangChain’s `@tool` decorator, we define any Python function as a callable tool. Here’s a basic **two-input** calculator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f934d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(\n",
    "    operation: Literal[\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "    a: Union[int, float],\n",
    "    b: Union[int, float],\n",
    ") -> Union[int, float]:\n",
    "    \"\"\"A simple calculator that adds, subtracts, multiplies, or divides two numbers.\"\"\"\n",
    "    # Handle edge cases\n",
    "    if operation == \"divide\" and b == 0:\n",
    "        return {\"error\": \"Division by zero is not allowed.\"}\n",
    "\n",
    "    # Perform the calculation\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    elif operation == \"multiply\":\n",
    "        return a * b\n",
    "    elif operation == \"divide\":\n",
    "        return a / b\n",
    "    else:\n",
    "        return \"unknown operation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccbde70",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "We use a type `Literal[...]` for the operation argument so the agent knows the tool takes one of these four operations.\n",
    "\n",
    "The function returns the calculation result (or an error message if dividing by zero).\n",
    "\n",
    "The returned value (even a dict with an error) will become the `“tool output”` that the agent can pass back to the LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491622b8",
   "metadata": {},
   "source": [
    "#### Building the Agent\n",
    "With the tool defined, we create the agent by calling `create_react_agent`. \n",
    "We need to provide:\n",
    "\n",
    "- The LLM model to use (via LangChain).\n",
    "\n",
    "- A list of tools (our calculator, and we could add more later).\n",
    "\n",
    "- A system prompt that explains the agent’s role or instructions.\n",
    "\n",
    "- Optionally, a state schema if we want to track custom state (*we’ll do that later*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da142bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 1) Define a system prompt for the agent\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful arithmetic assistant who is an expert at using a calculator.\"\n",
    "    )   \n",
    "\n",
    "# 2) Initialize the LLM (ensure OPENAI_API_KEY is set)\n",
    "model = init_chat_model(model=\"openai:gpt-4o-mini\", api_key=\"sk-proj-***\", temperature=0.0)\n",
    "\n",
    "# 3) Create the agent with the model and the calculator tool\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[calculator],\n",
    "    prompt=SYSTEM_PROMPT,\n",
    "    # state_schema defaults to AgentState\n",
    ").with_config({\"recursion_limit\": 20})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5368085",
   "metadata": {},
   "source": [
    "**Key points:**\n",
    "\n",
    "`init_chat_model` loads a chat model (here *gpt-4o-mini*). You can also use `ChatOpenAI` directly. The `temperature=0.0` makes it deterministic.\n",
    "``create_react_agent`` returns a compiled state graph (the agent). We pass our single calculator tool in a list.\n",
    "We set `recursion_limit` to 20 to prevent the agent from looping forever calling tools. This is the max number of **LLM→tool** steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49151f",
   "metadata": {},
   "source": [
    "#### Visualize the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677895e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97a34b",
   "metadata": {},
   "source": [
    "Invoking the Agent\n",
    "To use the agent, we call `agent.invoke(...)` with an input message. The message format is a list of messages (like in LangChain). \n",
    "Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49657afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧑 Human: What is 3.1 * 4.2?\n",
      "📝 AI:\n",
      "    🔧 Tool Call: calculator \n",
      "        Args: {'operation': 'multiply', 'a': 3.1, 'b': 4.2}\n",
      "🛠️ Tool Output: 13.020000000000001\n",
      "📝 AI: The result of \\( 3.1 \\times 4.2 \\) is approximately \\( 13.02 \\).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage ,ToolMessage\n",
    "\n",
    "# Local helper to pretty-print message history\n",
    "def FormatMessages(messages):\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"🧑 Human: {message.content}\")\n",
    "        elif hasattr(message, \"tool_calls\") and getattr(message, \"tool_calls\"):\n",
    "            print(\"📝 AI:\")\n",
    "            for call in message.tool_calls:\n",
    "                name = call.get(\"name\")\n",
    "                args = call.get(\"args\")\n",
    "                print(f\"    🔧 Tool Call: {name} \")\n",
    "                print(f\"        Args: {args}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"🛠️ Tool Output: {message.content}\")\n",
    "        else:\n",
    "            content = getattr(message, \"content\", \"\")\n",
    "            if content:\n",
    "                print(f\"📝 AI: {content}\")\n",
    "\n",
    "result1 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What is 3.1 * 4.2?\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "FormatMessages(result1[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe56d56",
   "metadata": {},
   "source": [
    "This returns a dictionary representing the final state after the agent finishes. It includes a `\"messages\"` key, which is the full conversation history (including the assistant’s steps). We used a helper to print the messages:\n",
    "\n",
    "**User asks:** *“What is 3.1 * 4.2?”*\n",
    "\n",
    "**Agent (AI) decides** to use the calculator tool with `operation=\"multiply\"`, *a=3.1*, *b=4.2*. Notice this appears as an AIMessage with a `🔧 Tool Call`.\n",
    "\n",
    "**ToolNode executes:** It runs our calculator function, which returns *13.02*.\n",
    "\n",
    "`Tool output` (13.02) is added to the conversation as a `ToolMessage` (shown as 🛠️ Tool Output).\n",
    "\n",
    "Agent (AI) processes the tool output and gives the final answer: *“3.1 multiplied by 4.2 is 13.02.”*\n",
    "\n",
    "The loop stopped because the agent didn’t request any more tools after getting the result (*enough information to answer the user*).\n",
    "\n",
    "You could log this trace with [LangSmith](https://langchain.com/langsmith) for debugging. \n",
    "The important thing is: the agent alternates between the LLM deciding on an action and executing tools until done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a97170",
   "metadata": {},
   "source": [
    "How It Works: Graph, State, and Messages\n",
    "- Graph: create_react_agent compiles a LangGraph graph with an LLM node and a Tool node.\n",
    "- State: Defaults to AgentState, primarily a list of messages plus a remaining_steps counter.\n",
    "\n",
    "- Messages:\n",
    "    - LLM proposes tool calls via AIMessage(tool_calls=[...])\n",
    "    - Tool node executes registered tools and returns ToolMessage with tool_call_id\n",
    "    - LLM reads observations and decides next action or final answer\n",
    "\n",
    "Internals you’ll observe in traces:\n",
    "\n",
    "- Tool descriptions included in model call metadata\n",
    "- Matching tool_call_id across AI/tool messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac52a3a",
   "metadata": {},
   "source": [
    "#### Agent State and Messages\n",
    "LangGraph agents maintain a state, which is a typed dictionary tracking data throughout the execution. By default, the prebuilt agent uses `AgentState`, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d247a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypedDict, NotRequired, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages  # a reducer\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    remaining_steps: NotRequired[int]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1de88",
   "metadata": {},
   "source": [
    "The messages list holds all `BaseMessage` objects (human, AI, or tool messages). The special `add_messages` reducer appends new messages to this list automatically.\n",
    "\n",
    "`remaining_steps` (optional) tracks how many steps the graph is allowed to run before hitting the recursion limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebf744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"human\",\n",
      "    \"data\": {\n",
      "      \"content\": \"What is 3.1 * 4.2?\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"human\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"25f210a3-ed3b-4dbf-856d-6d606c09d9f6\",\n",
      "      \"example\": false\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ai\",\n",
      "    \"data\": {\n",
      "      \"content\": \"\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_ohicPHQiXrdCJSHmBJC7yB3L\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"operation\\\":\\\"multiply\\\",\\\"a\\\":3.1,\\\"b\\\":4.2}\",\n",
      "              \"name\": \"calculator\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ],\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "          \"completion_tokens\": 26,\n",
      "          \"prompt_tokens\": 105,\n",
      "          \"total_tokens\": 131,\n",
      "          \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          },\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "        \"system_fingerprint\": \"fp_560af6e559\",\n",
      "        \"id\": \"chatcmpl-CLoO3SENRsHVWKwXLjcIeRdY917fS\",\n",
      "        \"service_tier\": \"default\",\n",
      "        \"finish_reason\": \"tool_calls\",\n",
      "        \"logprobs\": null\n",
      "      },\n",
      "      \"type\": \"ai\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"run--2b25c0cf-3d05-4f47-b1c3-15cde96fbb6e-0\",\n",
      "      \"example\": false,\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"calculator\",\n",
      "          \"args\": {\n",
      "            \"operation\": \"multiply\",\n",
      "            \"a\": 3.1,\n",
      "            \"b\": 4.2\n",
      "          },\n",
      "          \"id\": \"call_ohicPHQiXrdCJSHmBJC7yB3L\",\n",
      "          \"type\": \"tool_call\"\n",
      "        }\n",
      "      ],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 105,\n",
      "        \"output_tokens\": 26,\n",
      "        \"total_tokens\": 131,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"tool\",\n",
      "    \"data\": {\n",
      "      \"content\": \"13.020000000000001\",\n",
      "      \"additional_kwargs\": {},\n",
      "      \"response_metadata\": {},\n",
      "      \"type\": \"tool\",\n",
      "      \"name\": \"calculator\",\n",
      "      \"id\": \"c7593da4-5ab7-4c7d-bdaf-08a16c34f29e\",\n",
      "      \"tool_call_id\": \"call_ohicPHQiXrdCJSHmBJC7yB3L\",\n",
      "      \"artifact\": null,\n",
      "      \"status\": \"success\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ai\",\n",
      "    \"data\": {\n",
      "      \"content\": \"The result of \\\\( 3.1 \\\\times 4.2 \\\\) is approximately \\\\( 13.02 \\\\).\",\n",
      "      \"additional_kwargs\": {\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"response_metadata\": {\n",
      "        \"token_usage\": {\n",
      "          \"completion_tokens\": 26,\n",
      "          \"prompt_tokens\": 145,\n",
      "          \"total_tokens\": 171,\n",
      "          \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          },\n",
      "          \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "          }\n",
      "        },\n",
      "        \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "        \"system_fingerprint\": \"fp_560af6e559\",\n",
      "        \"id\": \"chatcmpl-CLoO5BK61nBfTMsiFTgxBj8oIjKG4\",\n",
      "        \"service_tier\": \"default\",\n",
      "        \"finish_reason\": \"stop\",\n",
      "        \"logprobs\": null\n",
      "      },\n",
      "      \"type\": \"ai\",\n",
      "      \"name\": null,\n",
      "      \"id\": \"run--17ae89dd-4a38-4aea-ba5f-092dba802db7-0\",\n",
      "      \"example\": false,\n",
      "      \"tool_calls\": [],\n",
      "      \"invalid_tool_calls\": [],\n",
      "      \"usage_metadata\": {\n",
      "        \"input_tokens\": 145,\n",
      "        \"output_tokens\": 26,\n",
      "        \"total_tokens\": 171,\n",
      "        \"input_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"cache_read\": 0\n",
      "        },\n",
      "        \"output_token_details\": {\n",
      "          \"audio\": 0,\n",
      "          \"reasoning\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import messages_to_dict\n",
    "import json\n",
    "\n",
    "print(json.dumps(messages_to_dict(result1[\"messages\"]), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d38d0",
   "metadata": {},
   "source": [
    "This outputs the full sequence of messages the agent exchanged, which can be helpful for debugging or understanding exactly what happened each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455a377",
   "metadata": {},
   "source": [
    "#### Access and Modify State From Within Tools\n",
    "Sometimes you need tools to **both** return an *observation* and *update extra state* (e.g., an operation log). You can extend the default state and safely update it.\n",
    "\n",
    "#### Extending State: Custom Reducers\n",
    "One powerful feature of LangGraph is you can extend the agent’s state with your own fields. For example, maybe we want the agent to remember a history of operations it performed. We can define a custom state schema by subclassing `AgentState`.\n",
    "\n",
    "First, we write a reducer function for merging lists safely, Then we create a new state type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5150afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "\n",
    "def reduce_list(left: list | None, right: list | None) -> list:\n",
    "    \"\"\"Safely combine two lists (treat None as empty list).\"\"\"\n",
    "    left = left or []\n",
    "    right = right or []\n",
    "    return left + right\n",
    "\n",
    "class CalcState(AgentState):\n",
    "    \"\"\"Graph State with an operation log.\"\"\"\n",
    "    ops: Annotated[list[str], reduce_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb50652",
   "metadata": {},
   "source": [
    "Here, `ops` is a list of strings, and we use `reduce_list` to tell LangGraph how to combine values if multiple updates happen. This field will track what operations were done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90096332",
   "metadata": {},
   "source": [
    "#### Inject state and tool_call_id into the tool\n",
    "Use `InjectedState` to prevent the LLM from seeing/constructing the state argument. Use `InjectedToolCallId` to produce a proper `ToolMessage` that matches the call.\n",
    "\n",
    "When a tool needs to **read** or **update** the agent state, we use special annotations. The LLM itself never sees the full state, so the state object in a tool function must come from an injection by the framework.\n",
    "\n",
    "We modify our calculator tool to accept the state (and the `tool_call_id`) as injected arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a0db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def calculator_wstate(\n",
    "    operation: Literal[\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "    a: Union[int, float],\n",
    "    b: Union[int, float],\n",
    "    state: Annotated[CalcState, InjectedState],        # injected by LangGraph\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],  # injected by LangGraph\n",
    ") -> Command:\n",
    "    \"\"\"Calculator tool that updates state with the operation.\"\"\"\n",
    "    # Perform calculation\n",
    "    if operation == \"divide\" and b == 0:\n",
    "        result = \"error: division by zero\"\n",
    "    elif operation == \"add\":\n",
    "        result = a + b\n",
    "    elif operation == \"subtract\":\n",
    "        result = a - b\n",
    "    elif operation == \"multiply\":\n",
    "        result = a * b\n",
    "    elif operation == \"divide\":\n",
    "        result = a / b\n",
    "    else:\n",
    "        result = \"unknown operation\"\n",
    "    \n",
    "    # Prepare an entry for the operation history\n",
    "    ops_entry = f\"({operation}, {a}, {b})\"\n",
    "    \n",
    "    # Return a Command that updates state\n",
    "    return Command(\n",
    "        update={\n",
    "            \"ops\": [ops_entry],  # adds to the list of ops\n",
    "            \"messages\": [\n",
    "                ToolMessage(str(result), tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94182d09",
   "metadata": {},
   "source": [
    "**How this works:**\n",
    "\n",
    "The state parameter is annotated with `InjectedState`, so LangGraph uses the current graph state (a `CalcState` object) when calling this function. The LLM never sees the state content during thought.\n",
    "\n",
    "`tool_call_id` is similarly injected to link the `ToolMessage` to the original call.\n",
    "\n",
    "Instead of returning the raw result, the tool returns a `Command` with an update dictionary. This tells LangGraph to:\n",
    "- Append `ops_entry` to the `ops` list in state.\n",
    "- Append a `ToolMessage` with the result content to messages in state.\n",
    "\n",
    "The messages key in update with a `ToolMessage` is how we feed the tool’s output back to the LLM. It works like our previous example, but now we manage state updates explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad574d",
   "metadata": {},
   "source": [
    "#### Create an agent with the new state schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a helpful arithmetic assistant who is an expert at using a calculator.\"\n",
    "\n",
    "model = init_chat_model(model=\"openai:gpt-4o-mini\", api_key=\"sk-proj-***\", temperature=0.0)\n",
    "tools = [calculator_wstate]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=SYSTEM_PROMPT,\n",
    "    state_schema=CalcState,     # custom state\n",
    ").with_config({\"recursion_limit\": 20})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0cafc",
   "metadata": {},
   "source": [
    "#### Run and inspect state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(multiply, 3.1, 4.2)']\n"
     ]
    }
   ],
   "source": [
    "result2 = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What is 3.1 * 4.2?\"}\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# we can inspect the ops list:\n",
    "print(result2[\"ops\"])  # access the custom state field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f9050",
   "metadata": {},
   "source": [
    "#### Parallel tool calls Example\n",
    "The tool node can execute multiple tool calls in parallel when the LLM proposes them in a **single step**. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6905b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧑 Human: What is 3.1 * 4.2 + 5.5 * 6.5?\n",
      "📝 AI:\n",
      "    🔧 Tool Call: calculator_wstate \n",
      "        Args: {'operation': 'multiply', 'a': 3.1, 'b': 4.2}\n",
      "    🔧 Tool Call: calculator_wstate \n",
      "        Args: {'operation': 'multiply', 'a': 5.5, 'b': 6.5}\n",
      "🛠️ Tool Output: 13.020000000000001\n",
      "🛠️ Tool Output: 35.75\n",
      "📝 AI:\n",
      "    🔧 Tool Call: calculator_wstate \n",
      "        Args: {'operation': 'add', 'a': 13.020000000000001, 'b': 35.75}\n",
      "🛠️ Tool Output: 48.77\n",
      "📝 AI: The result of \\( 3.1 \\times 4.2 + 5.5 \\times 6.5 \\) is \\( 48.77 \\).\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result3 = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is 3.1 * 4.2 + 5.5 * 6.5?\"}]\n",
    "})\n",
    "print(FormatMessages(result3[\"messages\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5332cba",
   "metadata": {},
   "source": [
    "**What happens here:**\n",
    "\n",
    "The LLM emits two tool calls at once: one to multiply 3.1 by 4.2, and another to multiply 5.5 by 6.5. The agent framework runs them in parallel.\n",
    "\n",
    "There are two 🛠️ Tool Outputs (one for each multiplication).\n",
    "\n",
    "The LLM then sees both results and issues a final tool call to add them together.\n",
    "\n",
    "After that tool call, it returns the final answer.\n",
    "\n",
    "The history (ops) is updated with all operations in order:\n",
    "\n",
    "`[\"(multiply, 3.1, 4.2)\", \"(multiply, 5.5, 6.5)\", \"(add, 13.02, 35.75)\"]`\n",
    "\n",
    "This demonstrates how the agent can chain and combine tool usage to solve more complex tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
